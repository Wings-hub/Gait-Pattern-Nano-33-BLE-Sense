%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Elmar Wings     					%
% 
% Literaturstellen					%
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@InProceedings{Abadi:2016,
  author    = {Abadi, Mart{\'\i}n and  Barham, Paul and Chen, Jianmin  and  Chen, Zhifeng and  Davis, Andy and  Dean, Jeffrey and Devin, Matthieu  and Ghemawat, Sanjay  and Irving, Geoffrey  and Isard, Michael  and Kudlur, Manjunath  and Levenberg, Josh  and Monga, Rajat  and Moore, Sherry  and Murray, Derek G.  and Steiner, Benoit  and Tucker, Paul  and Vasudevan, Vijay  and Warden, Pete  and Wicke, Martin  and  Yu, Yuan and Zheng, Xiaoqiang },
  booktitle = {12\textsuperscript{th} {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
  title     = {TensorFlow: A System for Large-Scale Machine Learning},
  year      = {2016},
  address   = {Savannah, GA},
  month     = nov,
  pages     = {265--283},
  publisher = {{USENIX} Association},
  isbn      = {978-1-931971-33-1},
  url       = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
}

@article{Agarap:2018,
  author      = {Agarap, Abien Fred },
  title       = {Deep Learning using Rectified Linear Units (ReLU)},
  abstract    = {We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer $h_{n - 1}$ in a neural network, then multiply it by weight parameters $\theta$ to get the raw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$, i.e. $f(o) = \max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide class predictions $\hat{y}$ through argmax function, i.e. argmax $f(x)$.},
  date        = {2018-03-22},
  eprint      = {1803.08375},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  url         = {https://arxiv.org/pdf/1803.08375v2},
  keywords    = {cs.NE, cs.CV, cs.LG, stat.ML},
}

@Inproceedings{Agarap:2018b,
  author    = {Agarap, Abien Fred M.},
  title     = {On Breast Cancer Detection: An Application of Machine Learning Algorithms on the Wisconsin Diagnostic Dataset},
  year      = {2018},
  isbn      = {9781450363365},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3184066.3184080},
  doi       = {10.1145/3184066.3184080},
  abstract  = {This paper presents a comparison of six machine learning (ML) algorithms: GRU-SVM[1], Linear Regression, Multilayer Perceptron (MLP), Nearest Neighbor (NN) search, Softmax Regression, and Support Vector Machine (SVM) on the Wisconsin Diagnostic Breast Cancer (WDBC) dataset[2] by measuring their classification test accuracy, and their sensitivity and specificity values. The said dataset consists of features which were computed from digitized images of FNA tests on a breast mass[2]. For the implementation of the ML algorithms, the dataset was partitioned in the following fashion: 70\% for training phase, and 30% for the testing phase. The hyper-parameters used for all the classifiers were manually assigned. Results show that all the presented ML algorithms performed well (all exceeded 90% test accuracy) on the classification task. The MLP algorithm stands out among the implemented algorithms with a test accuracy of ≈99.04%.},
  booktitle = {Proceedings of the 2nd International Conference on Machine Learning and Soft Computing},
  pages     = {5--9},
  numpages  = {5},
  keywords  = {classification, support vector machine, machine learning, nearest neighbors, artificial neural networks, supervised learning, linear regression, multilayer perceptron, wisconsin diagnostic breast cancer dataset, artificial intelligence, softmax regression},
  location  = {Phu Quoc Island, Viet Nam},
  series    = {ICMLSC '18},
  note      = {\href{https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)}{Link}, \href{https://www.kaggle.com/uciml/breast-cancer-wisconsin-data}{Link}},
}


@book{Akremi:2011,
  title     = {Datenanalyse mit SPSS für Fortgeschrittene 1 – Datenaufbereitung und uni- und bivariate Statistik},
  editor    = {Akremi, Leila and Baur, Nina and Fromm, Sabine},
  volume    = {3},
  year      = {2011},
  publisher = {Springer Fachmedien}
}

@online{Alake:2020,
 abstract = {The main content of this article will present how the AlexNet Convolutional Neural Network(CNN) architecture is implemented using TensorFlow and Keras. AlexNet was first utilized in the public$\ldots$},
 author   = {Alake, Richmond},
 year     = {14.08.2020},
 title    = {Implementing AlexNet CNN Architecture Using TensorFlow 2.0+ and Keras},
 url      = {https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98},
 urldate  = {11.11.2020},
}

@article{Alzubaidi:2021,
  author  = {Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and Al-Dujaili, Ayad and  Duan, Ye and Al-Shamma, Omran and Santamaría, J.and Fadhel, Mohammed A. and Al-Amidie, Muthana and Farhan, Laith},
  year    = 2021,
  titel   = {Review of deep learning: concepts, CNN architectures, challenges, applications, future directions},
  journal = {Journal of Big Data},
  number  = 53,
  volume  = 8,
  doi     = {https://doi.org/10.1186/s40537-021-00444-8},
  note    = {\textcolor{blue}{\href{../../MLbib/CNN/s40537-021-00444-8.pdf}{[pdf]}}},
}

@TechReport{Alom:2018,
  title         = {The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches}, 
  author        = {Alom, Md Zahangir  and Taha, Tarek M.  and  Yakopcic, Christopher and  Westberg, Stefan and Sidike, Paheding  and Nasrin,  Mst Shamima  and  Van Esesn, Brian C. and Awwal, Abdul A. S.  and Asari, Vijayan K.},
  year          = {2018},
  institute     = {Cornell university},
  eprint        = {1803.01164},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  note          = {\textcolor{blue}{\href{../../MLbib/CNN/1803.01164.pdf}{[pdf]}}},
}

@online{AnacondaIntel:2020,
  editor  = {{Anaconda Inc.}},
  year    = {2020},
  title   = {Anaconda Cloud - Intel},
  url     = {https://anaconda.org/intel},
  urldate = {16.07.2020},
}

@article{Anderson:1935,
  author    = {Anderson, Edgar},
  journal   = {Bulletin of the American Iris Society},
  number    = {59},
  pages     = {2-5},
  title     = {The irises of the Gaspé Peninsula},
  year      = {1935},
}

@article{Anderson:1936,
  ISSN      = {00266493},
  URL       = {http://www.jstor.org/stable/2394164},
  author    = {Anderson, Edgar},
  journal   = {Annals of the Missouri Botanical Garden},
  number    = {3},
  pages     = {457--509},
  publisher = {Missouri Botanical Garden Press},
  title     = {The Species Problem in Iris},
  volume    = {23},
  year      = {1936},
  doi       = {10.2307/2394164},
}

@book{Anderson:1988,
  title     = {Neurocomputing},
  author    = {Anderson, James A. and Rosenfeld, Edward and Pellionisz, Andras},
  volume    = {2},
  year      = {1988},
  publisher = {MIT Press}
}

@online{Arducam:2021,
  editor  = {Arducam},
  year    = {2021},  
  title   = {{Featured Camera Modules Supported}},
  url     = {https://www.arducam.com/docs/usb-cameras/featured-camera-modules-supported/},
  urldate = {2021-06-16},
} 


@online{Arduino:2019SPI,
  editor  = {Arduino},
  year    = {2019},  
  title   = {{SPI Library}},
  url     = {https://www.arduino.cc/en/reference/SPI},
  urldate = {2021-06-09},
} 

@online{Arduino:2019I2S,
  editor  = {Arduino},
  year    = {2019},  
  title   = {{I2S Library}},
  url     = {https://www.arduino.cc/en/Reference/I2S},
  urldate = {2021-06-09},
} 

@online{Arduino:2021,
  editor    = {{Arduino}},
  year      = 2021,
  ALTauthor = {Arduino},
  ALTeditor = {Arduino},
  title     = {Arduino Nano 33 BLE},
  date      = {03.05.2021},
  url       = {https://store.arduino.cc/usa/nano-33-ble-sense},
}

@Article{Artamonov:2018,
  author  = {Artamonov, N. S. and Yakimov, P. Y.},
  title   = {Towards Real-Time Traffic Sign Recognition via YOLO on a Mobile GPU},
  year    = 2018,
  journal = {Journal of Physics : Conference Series},
  series  = 1096,
  doi     = {10.1088/1742-6596/1096/1/012086}
}

@online{Arunava:2018,
  abstract = {In this article, we will see what are Convolutional Neural Networks, ConvNets in short. ConvNets are the superheroes that took working with images in deep learning to the next level. With ConvNets$\ldots$},
  author   = {Arunava},
  year     = {2018},
  title    = {Convolutional Neural Network - Towards Data Science},
  url      = {https://towardsdatascience.com/convolutional-neural-network-17fb77e76c05},
  urldate  = {08.11.2020},
}

@article{Ashraf:2018,
  author    = {Ashraf, M. Usman  and  Eassa, Fathy Alburaei and  Albeshri, Aiiad Ahmad and  Algarni, Abdullah},
  journal   = {{IEEE} Access},
  title     = {Performance and Power Efficient Massive Parallel Computational Model for {HPC} Heterogeneous Exascale Systems},
  year      = {2018},
  pages     = {23095--23107},
  volume    = {6},
  doi       = {10.1109/access.2018.2823299},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@online{AstaNV:2020,
  author  = {AstaNV},
  year    = {2020},
  title   = {TensorRT Python Sample for Object Detection},
  url     = {https://github.com/AastaNV/TRT_object_detection},
  urldate = {24/01/2020},
}

@online{Aufranc:2020,
  author  = {Aufranc, Jean-Luc},
  year    = {2020},  
  title   = {Sipeed MaixCube is a Fully Integrated AI Development Platform Powered by Kendryte K210 RISC-V SoC},
  url     = {https://www.cnx-software.com/2020/04/21/sipeed-maixcube-is-a-fully-integrated-ai-development-platform-powered-by-kendryte-k210-risc-v-soc/},
  urldate = {2021-06-16},
}

@online{Azevedo:2008,
 author = {Azevedo, Ana and Santos, M. F.},
 title  = {KDD, SEMMA AND CRISP-DM: A PARALLEL OVERVIEW},
 url    = {https://recipp.ipp.pt/bitstream/10400.22/136/3/KDD-CRISP-SEMMA.pdf},
 year   = 2008,
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% B
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{bai:2019,
  author    = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
  title     = {ONNX: Open Neural Network Exchange},
  year      = {2019},
  url       = {https://onnx.ai},
}
@InProceedings{Bakhoda:2009,
  author    = {Bakhoda, Ali  and Yuan, George L.  and Fung, Wilson W. L.  and Wong, Henry  and Aamodt, Tor M. },
  booktitle = {2009 {IEEE} International Symposium on Performance Analysis of Systems and Software},
  title     = {Analyzing {CUDA} workloads using a detailed {GPU} simulator},
  year      = {2009},
  month     = {apr},
  publisher = {{IEEE}},
  doi       = {10.1109/ispass.2009.4919648},
}

@Article{Balachandran:2017,
  author   = {Balachandran, Bala M.  and Prasad, Shivika},
  title    = {Challenges and Benefits of Deploying Big Data Analytics in the Cloud for Business Intelligence},
  journal  = {Procedia Computer Science},
  volume   = 112,
  pages    = {1112--1122},
  year     = 2017,
  doi      = {10.1016/j.procs.2017.08.138},
  Keywords = {Cloud Computing, Big Data Analytics, Cloud Analytics, Security, Privacy, Business Intelligence, MapReduce, AaaS, CLaaS},
  note     = {\textcolor{blue}{\href{../ExterneDokumente/Meine.pdf}{[pdf]}}},
}

@Misc{Balakreshnan:2019,
  title  = {Inferencing Model - Jetson Nano Without Docker container},
  author = {Balakreshnan},
  year   = {2019},
  note   = {Eingesehen am 20.04.2020 [online]},
  url    = {https://github.com/balakreshnan/WorkplaceSafety/blob/master/InferencinginJetsonNano.md#inferencing-model---jetson-nano-without-docker-container}
}

@online{Beck.2018,
  abstract = {Diese Lernhilfe bietet eine Einf{\"u}hrung in die Grundlagen und Anwendungen neuronaler Netze},
  author   = {Beck, Fabian},
  year     = {2018},
  title    = {Neuronale Netze - Eine Einf{\"u}hrung - Aktivit{\"a}t},
  url      = {http://www.neuronalesnetz.de/aktivitaet.html},
  urldate  = {07.11.2020}
}


@Misc{Becker:2018,
  title  = {Transfer Learning – So können neuronale Netze voneinander lernen },
  author = {Becker, Roland},
  year   = {2018},
  note   = {Eingesehen am 30.01.2020 [online]},
  url    = {https://jaai.de/transfer-learning-1739/},
  key    = {Transferlearning}
}

@Misc{Becker:2018b,
  title  = {Machine / Deep Learning – Wie lernen künstliche neuronale Netze? },
  author = {Becker, Roland},
  year   = {2018},
  note   = {Eingesehen am 27.01.2020 [online]},
  url    = {https://jaai.de/machine-deep-learning-529/},
  key    = {Lernen}
}

@Online{Becker:2018c,
  abstract = {Ein wichtiges Merkmal von Systemen mit k{\"u}nstlicher Intelligenz ist die F{\"a}higkeit, selbst{\"a}ndig zu lernen. Anders als bei klassischer Software, die Probleme und Fragen auf Basis von vorher festgelegten Regeln abarbeitet, k{\"o}nnen selbstlernende Machine Learning Algorithmen die besten Regeln f{\"u}r die L{\"o}su},
  author   = {Becker, Roland},
  year     = {2018},
  title    = {Machine / Deep Learning - Wie lernen k{\"u}nstliche neuronale Netze?},
  url      = {https://jaai.de/machine-deep-learning-529/},
  urldate  = {12.11.2020}
}

@online{Behling:2019,
  author   = {Behling, Heinz},
  url      = {https://www.heise.de/ratgeber/Raspberry-GPIO-Pins-beim-Booten-initialisieren-4782030.html},
  editor   = {Heise Verlag},
  year     = 2019,
  date     = {26.06.2020},
}

@InProceedings{Berga:1991,
  author    = {Berg, T.B.  and Siegel, H.J. },
  booktitle = {[1991] Proceedings. The Fifth International Parallel Processing Symposium},
  title     = {Instruction execution trade-offs for {SIMD} vs. {MIMD} vs. mixed mode parallelism},
  year      = {1991},
  publisher = {{IEEE} Comput. Soc. Press},
  doi       = {10.1109/ipps.1991.153795},
}

@Inbook{Binder:2009,
  editor    = {Binder, Marc D.	and Hirokawa, Nobutaka and Windhorst, Uwe},
  title     = {Fast Fourier Transform},
  bookTitle = {Encyclopedia of Neuroscience},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {1558--1558},
  isbn      = {978-3-540-29678-2},
  doi       = {10.1007/978-3-540-29678-2_1683},
  url       = {https://doi.org/10.1007/978-3-540-29678-2_1683}
}


@article{Brachman:1994,
  abstract = {Knowledge Discovery in Databases},
  author   = {Brachman, Ronald J. and Anand, Tej},
  year     = {1994},
  title    = {The Process of Knowledge Discovery in Databases: A First Sketch},
  number   = {WS-94-03},
  journal  = {AAAI Technical Repor},
}

@online{Britz:2015,
  author  = {Britz, Denny},
  url     = {http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/},
  title   = {Understanding Convolutional Neural Networks for NLP},
  year    = {2015},
  urldate = {24/07/2020},
}

@online{Avago:2015,
  editor    = {{Avago Technologies}},
  year      = 2015,
  title     = {APDS-9960 - Digital Proximity, Ambient Light, RGB and Gesture Sensor},
  date      = {03.05.2021},
  url       = {https://docs.broadcom.com/doc/AV02-4191EN},
}

@article{Brown:2018,
  author    = {Brown, Noam and Sandholm, Tuomas},
  title     = {Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  volume    = {359},
  number    = {6374},
  pages     = {418--424},
  year      = {2018},
  doi       = {10.1126/science.aao1733},
  publisher = {American Association for the Advancement of Science},
  abstract  = {Pitting artificial intelligence (AI) against top human players demonstrates just how far AI has come. Brown and Sandholm built a poker-playing AI called Libratus that decisively beat four leading human professionals in the two-player variant of poker called heads-up no-limit Texas hold{\textquoteright}em (HUNL). Over nearly 3 weeks, Libratus played 120,000 hands of HUNL against the human professionals, using a three-pronged approach that included precomputing an overall strategy, adapting the strategy to actual gameplay, and learning from its opponent.Science, this issue p. 418No-limit Texas hold{\textquoteright}em is the most popular form of poker. Despite artificial intelligence (AI) successes in perfect-information games, the private information and massive game tree have made no-limit poker difficult to tackle. We present Libratus, an AI that, in a 120,000-hand competition, defeated four top human specialist professionals in heads-up no-limit Texas hold{\textquoteright}em, the leading benchmark and long-standing challenge problem in imperfect-information game solving. Our game-theoretic approach features application-independent techniques: an algorithm for computing a blueprint for the overall strategy, an algorithm that fleshes out the details of the strategy for subgames that are reached during play, and a self-improver algorithm that fixes potential weaknesses that opponents have identified in the blueprint strategy.},
  issn      = {0036-8075},
  URL       = {https://science.sciencemag.org/content/359/6374/418},
  eprint    = {https://science.sciencemag.org/content/359/6374/418.full.pdf},
  journal   = {Science}
}

@inproceedings{Brown:2017,
  title         = {Adversarial Patch}, 
  author        = {Brown, Tom B.  and  Mané, Dandelion and  Roy, Aurko and  Abadi, Martín and  Gilmer, Justin},
  booktitle     = {Neural Information Processing Systems - Machine Learning and Computer Security Workshop},
  year          = {2017},
  eprint        = {1712.09665},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  note          = {\textcolor{blue}{\href{../../MLbib/Adversarial/1712.09665.pdf}{[pdf]}}},  
}

@book{Brownlee:2016,
  title     = {Deep learning with Python: develop deep learning models on Theano and TensorFlow using Keras},
  author    = {Brownlee, Jason},
  year      = {2016},
  publisher = {Machine Learning Mastery},
}

@book{Buxmann:2019,
  title     = {K{\"u}nstliche Intelligenz},
  author    = {Buxmann, Peter and Schmidt, Holger},
  year      = {2019},
  publisher = {Springer}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% C
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{Caffe:2020,
  author  = {Jia, Yangqing and Evan Shelhamer, Evan},
  year    = {2020},
  title   = {Caffe},
  editor  = {Berkeley Artificial Intelligence Research},
  url     = {http://caffe.berkeleyvision.org/},
  urldate = {24/07/2020},
}

@online{Caffe2:2020,
  year    = {2020},
  title   = {Caffe2},
  editor  = {Facebook Open Source},
  url     = {https://caffe2.ai/},
  urldate = {24/07/2020},
}


@online{Campbell:2021,
  author  = {Campbell, Scott},
  year    = {2021},  
  title   = {{Basics of UART Communication}},
  url     = {https://www.circuitbasics.com/basics-uart-communication/},
  urldate = {2021-06-09},
} 

@online{Ceunen.02.12.2019,
 abstract = {Computer vision is an interesting topic lately due to autonomous cars, augmented reality, ANPR cameras, etc.},
 author   = {Ceunen, Bouwe},
 year     = {2019},
 title    = {Computer Vision With Jetson Nano - Technology at Rombit - Medium},
 url      = {https://medium.com/technology-at-rombit/computer-vision-with-jetson-nano-bccf8e6c6256},
 keywords = {Object Detection, Jetson Nano, TensorRT, OpenCV, TensorFlow, uff},
 urldate  = {29.10.2020},
}

@online{Chainer:2020,
  year    = {2020},
  title   = {Chainer},
  editor  = {Preferred Networks, Inc.},
  url     = {https://chainer.org/},
  urldate = {24/07/2020},
}

@Article{Chapman:2000,
 author = {Chapman, Pete and Clinton, Julian and Kerber, Randy and Khabaza, Thomas and Reinartz, Thomas and Shearer, Colin and Wirth, R{\"u}diger},
 title  = {CRISP-DM 1.0: Step-by-step data mining guide},
 url    = {https://www.semanticscholar.org/paper/CRISP-DM-1.0%3A-Step-by-step-data-mining-guide-Chapman-Clinton/54bad20bbc7938991bf34f86dde0babfbd2d5a72},
 year   = {2000},
}

@Article{Chetlur:2014,
  author      = {Chetlur, Sharan and  Woolley, Cliff and  Vandermersch, Philippe and  Cohen, Jonathan and  Tran, John and  Catanzaro, Bryan and  Shelhamer, Evan},
  title       = {cuDNN: Efficient Primitives for Deep Learning},
  abstract    = {We present a library of efficient implementations of deep learning primitives. Deep learning workloads are computationally intensive, and optimizing their kernels is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS). However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, although similarly to the BLAS library, these routines could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption.},
  date        = {2014-10-03},
  year        = 2014,
  eprint      = {1410.0759},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  journal     = {arXivLabs},
  url         = {https://arxiv.org/pdf/1410.0759v3},
  keywords    = {cs.NE, cs.LG, cs.MS},
}

@online{Chocolatey:2016,
  editor  = {Chocolatey Software},
  url     = {\url{https://chocolatey.org/install/}},
  title   = {Install Chocolatey},
  year    = {2016},
  urldate = {22/05/2016},
}

@misc{Chowdhery:2019,
  title         = {Visual Wake Words Dataset}, 
  author        = {Chowdhery, Aakanksha and  Warden, Pete and  Shlens, Jonathon and  Howard, Andrew and  Rhodes, Rocky},
  year          = {2019},
  eprint        = {1906.05721},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  url           = {https://github.com/Mxbonn/visualwakewords},
  note          = {\textcolor{blue}{\href{../../MLbib/Dataset/1906.05721.pdf}{[pdf]}, \textcolor{blue}{\href{https://github.com/Mxbonn/visualwakewords}{[github]}} }},  
}



@Article{Cielo2019SpeedingSA,
  author        = {Cielo, Salvatore and Iapichino, Luigi and  Baruffa, Fabio},
  journal       = {ArXiv},
  title         = {Speeding simulation analysis up with yt and Intel Distribution for Python},
  year          = {2019},
  eprint        = {1910.07855},
  archivePrefix = {arXiv},
  volume        = {abs/1910.07855},
}

@misc{CeTrade:2018,
  editor  = {{CE Trade}},
  note    = {\url{https://www.ce-trade.de/2018/10/19/acer-ruestet-predator-orion-gaming-desktops-auf/}},
  title   = {Acer rüstet Predator Orion-Gaming-Desktops auf},
  year    = {2018},
  urldate = {19/10/2018},
}


@Online{Coco:2021,
  author    = {Lin, Tsung-Yi and  Patterson, Genevieve and Ronchi, Matteo R.  and Cui, Yin  and  Maire, Michael and  Belongie, Serge and  Bourdev, Lubomir and  Girshick, Ross and  Hays, James and  Perona, Pietro and Ramanan, Deva  and Zitnick, Larry  and  Dollár, Piotr},
  title     = {COCO - Common Objects in Context},
  url       = {https://cocodataset.org/},
  date      = {15.05.2021},
  year      = 2021,
}  
%  note      = {\href{../../ExterneDokumente/Dataset/.pdf}{[pdf]}},



@online{CUDA:2020,
  year    = {2020},
  title   = {CUDA},
  editor  = {NVIDIA Corporation},
  url     = {https://developer.nvidia.com/cuda-zone},
  urldate = {24/07/2020},
}

@misc{CudaCompability:2020,
  title   = {CUDA Compatibility :: GPU Deployment and Management},
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://docs.nvidia.com/deploy/cuda-compatibility/index.html}},
  year    = {2020},
  urldate = {24/07/2020},
}

@manual{CUDATK:2020,
  year    = {2020},
  title   = {NVIDIA CUDA Tolkit 11.0.161},
  editor = {{NVIDIA Corporation}},
  urldate = {24/07/2020},
  note    = {\href{../../ExterneDokumente/CUDA/CUDA_Toolkit_Release_Notes.pdf}{[pdf]}},
}

@online{cuDNN:2020,
  year    = {2020},
  title   = {{NVIDIA cuDNN Documentation}},
  editor  = {{NVIDIA Corporation}},
  url     = {https://docs.nvidia.com/deeplearning/cudnn/developer-guide},
  urldate = {24/07/2020},
}

@online{cuDNN:2020a,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://developer.nvidia.com/cudnn}},
  title   = {NVIDIA cuDNN},
  year    = {2020},
  urldate = {06/06/2020},
}


@online{CuDNNCompability:2020,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html}},
  title   = {CUDNN Compatibility},
  year    = {2020},
  urldate = {01/06/2020},
}

@online{jetpack:2021,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://developer.nvidia.com/embedded/jetpack}},
  title   = {NVIDIA JetPack},
  year    = {2021},
  urldate = {20/04/2021},
}

@online{Jetson:2021DevKit,
  editor  = {{NVIDIA Corporation}},
  year    = {2021},  
  title   = {Jetson Nano 2GB Developer Kit },
  url     = {https://developer.nvidia.com/embedded/jetson-nano-2gb-developer-kit},
  urldate = {2021-06-16},
}


@online{SDCards:2020,
  url    = {https://elinux.org/RPi_SD_cards},
  year   = 2020,
  title  = {RPi SD cards},
  editor = {elinux.org},
}  

@online{JetsonDatasheet:2019,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://www.nvidia.com/de-de/autonomous-machines/embedded-systems/jetson-nano/product-development/}},
  title   = {Jetson Nano - Die Leistung moderner KI auf Millionen von Geräten},
  year    = {2019},
  urldate = {19/03/2019},
}

@online{Jetson:2020YouTube,
  editor  = {NVIDIA Developer},
  year    = {2020},  
  title   = {{Real-Time Object Detection in 10 Lines of Python Code on Jetson Nano }},
  url     = {https://www.youtube.com/watch?v=bcM5AQSAzUY&t=49s&ab_channel=NVIDIADeveloper},
  urldate = {2021-06-16},
}


@Online{NVIDIA.23.10.2020,
  abstract = {The Getting Started With TensorFlow In DIGITS guide provides an overview on using DIGITS with TensorFlow.},
  editor   = {NVIDIA},
  year     = {23.10.2020},
  title    = {Getting Started With TensorFlow In DIGITS :: NVIDIA Deep Learning DIGITS Documentation},
  url      = {https://docs.nvidia.com/deeplearning/digits/digits-getting-started-tensorflow/index.html},
  keywords = {DIGITS, TensorFlow},
  urldate  = {29.10.2020}
}


@online{NVIDIA.27.10.2020,
  abstract = {This guide provides instructions for installing TensorFlow for Jetson Platform.},
  editor   = {NVIDIA},
  year     = {2020},
  title    = {Installing TensorFlow For Jetson Platform :: NVIDIA Deep Learning Frameworks Documentation},
  url      = {https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html},
  keywords = {TensorFlow, Jetson Nano},
  urldate  = {29.10.2020}
}

@online{JetsonFlash:2020,
  editor = {{NVIDIA Corporation}},
  url    = {\url{https://docs.nvidia.com/jetson/l4t/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/flashing.html}},
  title  = {NVIDIA Jetson Linux Developer Guide : Flashing and Booting},
  year   = {2020},
  urldate = {24/07/2020},
}

@online{JetsonTensorFlow:2020,
  editor = {{NVIDIA Corporation}},
  url    = {\url{https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html}},
  title  = {Installing TensorFlow For Jetson Platform},
  year   = {2020},
  urldate = {24/07/2020},
}

@online{TensorRT:2015,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://developer.nvidia.com/tensorrt}},
  title   = {NVIDIA TensorRT},
  year    = {2015},
  urldate = {11/11/2015},
}

@online{TensorRTCompability:2020,
  editor  = {{NVIDIA Corporation}},
  url     = {\url{https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html}},
  title   = {TensorRT Compatibility Archive},
  year    = {2020},
  urldate = {11/11/2020},
}

@manual{TensorRT:2020,
  editor = {{NVIDIA Corporation}},
  year   = 2020,
  title  = "{TensorRT}",
  url    = {https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/graphsurgeon/graphsurgeon.html},
}

@online{NvidiaTensorRTAcc:2015,
  editor  = {{NVIDIA Corporation}},
  url    = {\url{https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html}},
  title   = {Accelerate Interference with TensorRT},
  year    = {2020},
  urldate = {29/07/2020},
}

@manual{JetsonHelloWorld:2020,
  editor = {{NVIDIA Corporation}},
  year   = 2020,
  title  = "{Two Days to a Demo}",
  url    = "https://developer.nvidia.com/embedded/twodaystoademo",
}

@manual{JetsonProjects:2020,
  editor = {{NVIDIA Corporation}},
  year   = 2020,
  title  = "{Jetson Community Projects}",
  url    = "https://developer.nvidia.com/embedded/community/jetson-projects",
}

@manual{JetsonUserGuide:2019,
  title   = {Jetson Nano Developer Kit - User Guide},
  year    = 2019,
  editor  = {{NVIDIA Corporation}},
  edition = 3,    
}

@online{JetsonGettingStarted:2019,
  title   = {Getting Started With Jetson Nano Developer Kit},
  year    = 2019,
  editor  = {{NVIDIA Corporation}},
  url     = {https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit},
  urldate = {29/07/2020},
}

@manual{JetsonUserManual:2019,
  title  = {Jetson Nano Developer Kit - User Guide},
  year   = 2019,
  editor = {{NVIDIA Corporation}},
  url    = "https://docs.nvidia.com/jetson/index.html",  
}

@manual{JetsonUserManual:2020,
  title  = {Jetson Nano Developer Kit - JetPack SD Card Image},
  year   = 2021,
  editor = {{NVIDIA Corporation}},
  url    = {https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit},  
}

@manual{JetPackOS:2021,
  title  = {Jetson Nano Developer Kit - User Guide},
  year   = 2020,
  editor = {{NVIDIA Corporation}},
  url = {https://developer.nvidia.com/embedded/jetpack},
}  


@article{Chablani:2017,
 abstract = {Compared to other region proposal classification networks (fast RCNN) which perform detection on various region proposals and thus end up performing prediction multiple times for various regions in a$\ldots$},
 author   = {Chablani, Manish},
 year     = {2017},
 title    = {YOLO --- You only look once, real time object detection explained},
 url      = {https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006},
 urldate  = {17.02.2021},
 journal  = {Towards Data Science},
}

@Misc{Chakrabarty:2015,	
  title  = {Application of Synthetic Minority Over-sampling Technique (SMOTe) for Imbalanced Datasets},
  author = {Chakrabarty; Navoneel},
  year   = {2015},
  note   = {Eingesehen am 28.12.2019 [online]},
  url    = {https://medium.com/towards-artificial-intelligence/application-of-synthetic-minority-over-sampling-technique-smote-for-imbalanced-data-sets-509ab55cfdaf},
  key    = {SMOTE-oversampling}
}

@InProceedings{Chaves:2006,
  author    = {Chaves, Ricardo and Kuzmanov, Georgi and Sousa, Leonel and Vassiliadis, Stamatis},
  editor    = {Goubin, Louis and Matsui, Mitsuru},
  title     = {Improving SHA-2 Hardware Implementations},
  booktitle = "Cryptographic Hardware and Embedded Systems - CHES 2006",
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {298--310},
  abstract  = {This paper proposes a set of new techniques to improve the implementation of the SHA-2 hashing algorithm. These techniques consist mostly in operation rescheduling and hardware reutilization, allowing a significant reduction of the critical path while the required area also decreases. Both SHA256 and SHA512 hash functions have been implemented and tested in the VIRTEX II Pro prototyping technology. Experimental results suggest improvements to related SHA256 art above 50{\%} when compared with commercial cores and 100{\%} to academia art, and above 70{\%} for the SHA512 hash function. The resulting cores are capable of achieving the same throughput as the fastest unrolled architectures with 25{\%} less area occupation than the smallest proposed architectures. The proposed cores achieve a throughput of 1.4 Gbit/s and 1.8 Gbit/s with a slice requirement of 755 and 1667 for SHA256 and SHA512 respectively, on a XC2VP30-7 FPGA.},
  isbn      = {978-3-540-46561-4},
  doi       = {doi.org/10.1007/​11894063},
}

@book{Chollet:2018,
  title     = {Deep Learning mit Python und Keras: Das Praxis-Handbuch vom Entwickler der Keras-Bibliothek},
  author    = {Chollet, Francois},
  year      = {2018},
  publisher = {MITP-Verlags GmbH \& Co. KG}
}

@online{CNTK:2020,
  year    = {2020},
  title   = {The Microsoft Cognitive Toolkit},
  editor  = {Microsoft},
  url     = {https://docs.microsoft.com/en-us/cognitive-toolkit/},
  urldate = {24/07/2020},
}

@phdthesis{Cooper:2018,
  author = {Cooper, Michael},
  year   = {2018},
  month  = {05},
  pages  = {},
  title  = {A Deep Learning Prediction Model for Mortgage Default A Deep Learning Prediction Model for Mortgage Default},
  doi    = {10.13140/RG.2.2.21506.12487}
}

@article{Corsten:1996,
  title   = {Anwendungsfelder Neuronaler Netze und ihre Umsetzung},
  author  = {Corsten, Hans and May, Constantin},
  journal = {Neuronale Netze in der Betriebswirtschaft-Anwendungen in Prognose, Klassifikation und Optimierung, Hrsg.: Corsten, H., May, C., Wiesbaden: Gabler},
  year    = {1996}
}

@online{Deeplearning4J:2020,
  year    = {2020},
  title   = {Deep Learning for Java},
  editor  = {Eclipse},
  url     = {https://deeplearning4j.org/},
  urldate = {24/07/2020},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% D
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{ITWissen:2017,
  editor  = {DATACOM Buchverlag GmbH },
  year    = {2017},
  title   = {FPU (floating point unit)},
  url     = {https://www.itwissen.info/FPU-floating-point-unit-Fliesskommaeinheit.html},
  urldate = {2021-04-13},
}


@online{ITWissen:2019,
  editor  = {DATACOM Buchverlag GmbH },
  year    = {2019},
  title   = {MOPS (million operations per second)},
  url     = {https://www.itwissen.info/MOPS-million-operations-per-second.html#:~:text=%C3%9Cber%20MOPS%20hinausgehende%20Rechenleistungen%20werden,einer%20Billion%20Operationen%20pro%20Sekunde.},
  urldate = {2021-04-13},
}

@online{Datenschutz:2021,
  editor  = {Datenschutz.org},
  year    = {2021},
  title   = {AES-Verschlüsselung: Advanced Encryption Standard},
  url     = {https://www.datenschutz.org/aes-verschluesselung/},
  urldate = {2021-04-13},
}

@online{Dejan:2021,
  author  = {Dejan},
  year    = {2021},  
  title   = {{How I2C Communication Works and How To Use It with Arduino}},
  url     = {https://howtomechatronics.com/tutorials/arduino/how-i2c-communication-works-and-how-to-use-it-with-arduino/},
  urldate = {2021-06-09},
} 

@article{Deng:2012,
  author  = {{Deng, L.}},
  journal = {IEEE Signal Processing Magazine}, 
  title   = {The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]}, 
  year    = {2012},
  volume  = {29},
  number  = {6},
  pages   = {141--142},
  note    = {\href{../../MLbib/Dataset/MNIST-SPM2012.pdf}{[pdf]}, \href{https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.7/tensorflow/g3doc/tutorials/mnist/download/index.md}{Link}},
}

@InProceedings{Deng:2009,
  author    = {Deng, J. and Dong, W. and Socher, R. and Li, L. and  Li, Kai and  Fei-Fei, Li},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title     = {ImageNet: A large-scale hierarchical image database}, 
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {248--255},
  doi       = {10.1109/CVPR.2009.5206848}},
  note      = {\href{http://www.image-net.org/download}{Link}, \href{https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/descriptio}{Link}}, 
}

@article{Deng:2014,
  title     = {Deep learning: methods and applications},
  author    = {Deng, Li and Yu, Dong},
  journal   = {Foundations and trends in signal processing},
  volume    = {7},
  number    = {3--4},
  pages     = {197--387},
  year      = {2014},
  publisher = {Now Publishers Inc. Hanover, MA, USA},
  doi       = {10.1561/2000000039},
  note      = {\href{../../MLbib/DeepLearning/DeepLearningMethodsAndApplications.pdf}{[pdf]}},
}

@misc{Dodge:2016,
  abstract = {Image quality is an important practical challenge that is often overlooked in the design of machine vision systems. Commonly, machine vision systems are trained and tested on high quality image datasets, yet in practical applications the input images can not be assumed to be of high quality. Recently, deep neural networks have obtained state-of-the-art performance on many machine vision tasks. In this paper we provide an evaluation of 4 state-of-the-art deep neural network models for image classification under quality distortions. We consider five types of quality distortions: blur, noise, contrast, JPEG, and JPEG2000 compression. We show that the existing networks are susceptible to these quality distortions, particularly to blur and noise. These results enable future work in developing deep neural networks that are more invariant to quality distortions.},
  author   = {Dodge, Samuel and Karam, Lina},
  date     = {14.04.2016},
  year     = 2016,
  title    = {Understanding How Image Quality Affects Deep Neural Networks},
  url      = {https://arxiv.org/pdf/1604.04004.pdf},
  urldate  = {11.11.2020},
}

@article{Donno:2010,
  author    = {Donno, Danilo De  and  Esposito, Alessandra and Tarricone, Luciano  and  Catarinucci, Luca},
  journal   = {{IEEE} Antennas and Propagation Magazine},
  title     = {Introduction to {GPU} Computing and {CUDA} Programming: A Case Study on {FDTD} [{EM} Programmer{\textquotesingle}s Notebook},
  year      = {2010},
  month     = {jun},
  number    = {3},
  pages     = {116--122},
  volume    = {52},
  doi       = {10.1109/map.2010.5586593},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@book{Dormann:2013,
  title     = {Datenanalyse mit SPSS für Fortgeschrittene 1 – Datenaufbereitung und uni- und bivariate Statistik},
  author    = {Dormann, Carsten F.},
  volume    = {2},
  year      = {2013},
  publisher = {Springer-Verlag}
}

@incollection{Dorn:2018,
  title     = {Neuronale Netze},
  author    = {D{\"o}rn, Sebastian},
  booktitle = {Programmieren f{\"u}r Ingenieure und Naturwissenschaftler},
  pages     = {89--148},
  year      = {2018},
  publisher = {Springer}
}

@article{Dusing.2000,
 author = {D{\"u}sing, Roland},
 year = {2000},
 title = {Knowledge Discovery in Databases},
 pages = {74--75},
 volume = {42},
 number = {1},
 issn = {1861-8936},
 journal = {Wirtschaftsinformatik},
 doi = {10.1007/BF03250720},
}

@Misc{Duden:2020,
  title  = {Serialisieren},
  editor = {Duden},
  year   = {2020},
  note   = {Eingesehen am 14.01.2020 [online]},
  url    = {https://www.duden.de/rechtschreibung/serialisieren}
}

@article{Dumoulin:2016,
  author      = {Dumoulin, Vincent  and Visin, Francesco },
  title       = {A guide to convolution arithmetic for deep learning},
  abstract    = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
  date        = {2016-03-23},
  eprint      = {1603.07285},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  url         = {https://arxiv.org/pdf/1603.07285v2},
  keywords    = {stat.ML, cs.LG, cs.NE},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% E
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{Elektronik-Kompendium:2020,
  author  = {Elektronik-Kompendium},
  year    = {2020},  
  title   = {{RISC-V (Prozessoren)}},
  url     = {https://www.elektronik-kompendium.de/sites/com/2501131.htm},
  urldate = {2021-06-01},
} 

@book{Ernst:2020,
  author    = {Ernst, Hartmut and Schmidt, Jochen and Beneken, Gerd Hinrich},
  year      = {2020},
  title     = {Grundkurs Informatik: Grundlagen und Konzepte f{\"u}r die erfolgreiche IT-Praxis -- eine umfassende, praxisorientierte Einf{\"u}hrung},
  address   = {Wiesbaden},
  edition   = {7., erweiterte und aktualisierte Auflage},
  publisher = {{Springer Vieweg} and {Springer Fachmedien Wiesbaden GmbH}},
  isbn      = {9783658303303},
  series    = {Lehrbuch}
}

@book{Ertel:2016,
  author    = {Ertel, Wolfgang},
  year      = {2016},
  title     = {Grundkurs K{\"u}nstliche Intelligenz},
  address   = {Wiesbaden},
  publisher = {{Springer Fachmedien Wiesbaden}},
  isbn      = {978-3-658-13548-5},
  doi       = {10.1007/978-3-658-13549-2},
}

@online{Exp:2018,
  editor  = {EXP GmbH},
  year    = {2018},
  title   = {Arduino Tutorial - Pulsweitenmodulation (PWM)},
  url     = {https://www.exp-tech.de/blog/arduino-tutorial-pulsweitenmodulation-pwm},
  urldate = {2021-04-13},
}

@INPROCEEDINGS{Eyobu:2018,
  author    = {Eyobu, Odongo Steven and Kim, Young Woo and Cha, Daewoong and Han, Dong Seog},
  booktitle = {2018 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title     = {A real-time sleeping position recognition system using IMU sensor motion data}, 
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1-2},
  doi       = {10.1109/ICCE.2018.8326209}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% F
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{FastAI:2020,
  year    = {2020},
  title   = {FastAI},
  editor  = {fast.ai},
  url     = {https://www.fast.ai/},
  urldate = {24/07/2020},
}

@article{Fayyad:1996, 
  author  = {Fayyad, Usama and Piatetsky-Shapiro, Gregory and Smyth, Padhraic}, 
  title   = {From Data Mining to Knowledge Discovery in Databases}, 
  jpurnal = {AI Magazine},
  volume  = {17}, 
  number  = {3}, 
  url     = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/1230}, 
  DOI     = {10.1609/aimag.v17i3.1230}, 
  year    = {1996}, 
  month   = {Mar.}, 
  pages   = {37},
  note    = {\href{../../ExterneDokumente/kdd/1230-Article Text-1227-1-10-20080129.pdf}{[pdf]}},
}

@Article{Ferrucci:2012,
  author  ={Ferrucci, D. A.},
  journal = {IBM Journal of Research and Development}, 
  title   = {Introduction to ``This is Watson''}, 
  year    = {2012},
  volume  = {56},
  number  = {3.4},
  pages   = {1:1-1:15},
  doi     = {10.1147/JRD.2012.2184356}}
}

@Article{Fisher:1936,
  author   = {Fisher, R. A.},
  title    = {The use of Multiple Measurements inTaxonomic Problems}},
  journal  = {Annals of Eugenics},
  volume   = {7},
  number   = {2},
  pages    = {179-188},
  doi      = {https://doi.org/10.1111/j.1469-1809.1936.tb02137.x},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
  abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
  year     = {1936},
  note     = {\href{../../ExterneDokumente/Dataset/j.1469-1809.1936.tb02137.x.pdf}{[pdf]}},
}

@Inproceedings{Folk:2011,
  author    = {Folk, M. and Heber, G. and Koziol, Q. and Pourmal, E. and Robinson, D.},
  year      = {2011},
  title     = {An overview of the HDF5 technology suite and its applications},
  booktitle = {EDBT/ICDT 2011},
  pages     = {36--47},
  doi       = {10.1145/1966895.1966900},
}


@Book{Funke:1998,
  title     = {Was ist Intelligenz?},
  author    = {Funke, J. and Vaterrodt-Pl"unnecke, B.},
  year      = 1998,
  publisher = {C.H. Beck Wissen},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% G
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@PhdThesis{Gennaro:1998,
  author = {Gennaro, Claudio},
  school = {Ph. D. Thesis-1995},
  title  = {Models for SIMD, MIMD and Hybrid Parallel Architectures},
  year   = {1998},
}


@online{Gerber:2018,
  author   = {Gerber, Tom},
  title    = {Grundlagen zu Einplatinenrechnern},
  year     = 2018,
  volume   = 18,
  page     = 156,
  journal  = {c't},
  url      = {https://www.heise.de/select/ct/2018/18/1535269458716343}
}

@article{Ghorpade:2012,
  author    = {Ghorpade, Jayshree},
  journal   = {Advanced Computing: An International Journal},
  title     = {{GPGPU} Processing in {CUDA} Architecture},
  year      = {2012},
  month     = {jan},
  number    = {1},
  pages     = {105--120},
  volume    = {3},
  doi       = {10.5121/acij.2012.3109},
  publisher = {Academy and Industry Research Collaboration Center ({AIRCC})},
}

@online{GitHubJetsonInferenceMaster:2020,
  author  = "dusty-nv",
  year    = 2020,
  title   = "{jetson-inference-master}",
  url     = {https://github.com/dusty-nv/jetson-inference},
  urldate = {24/01/2020},
}

@online{GitHub:2020,
  editor  = {{GitHub, Inc.}},
  year    = {2020},
  title   = {GitHub},
  url     = {https://github.com},
  urldate = {24/01/2020},
}

@online{GithubTensorflowBroken:2019,
  editor  = {{GitHub, Inc.}},
  url     = {\url{https://github.com/tensorflow/tensorflow/issues/36121}},
  title   = {TensorFlow Issue - Installation Broken},
  year    = {2020},
  urldate = {22/01/2020},
}

@book{Gluchowski:2006,
  title     = {Analytische Informationssysteme: Business Intelligence-Technologien und -Anwendungen},
  author    = {Gluchowski, Peter and Charmoni, Peter},
  volume    = {3},
  year      = {2006},
}

@misc{Goemann:2019,
  author  = {Goemann, Philipp},
  year    = {2019},  
  title   = {{Wenn die Maschine den Menschen schlägt - AlphaZero am Beispiel von 4-Gewinnt}},
  url     = {https://reposit.haw-hamburg.de/bitstream/20.500.12738/9166/1/thesis.pdf},
  urldate = {2021-06-01},
}
			


@article{Goodfellow:2014,
  title         = {Explaining and Harnessing Adversarial Examples}, 
  author        = {Goodfellow, Ian J.  and  Shlens, Jonathon and  Szegedy, Christian},
  year          = {2014},
  eprint        = {1412.6572},
  archivePrefix = {arXiv},
  primaryClass  = {stat.ML},
  journal       = {arXiv 1412.6572},
  note          = {\textcolor{blue}{\href{../../MLbib/Adversarial/1412.6572.pdf}{[pdf]}}},  
}

@online{GoogleCoral:2019,
  editor  = {Google},
  year    = {14/11/2019},
  title   = {Coral: Build beneficial and privacy preserving AI},
  url     = {https://coral.withgoogle.com/},
  urldate = {14/11/2019},
}

@online{GoogleTensorFlow:2019,
  editor  = {Google},
  year    = {14/11/2019},
  title   = {TensorFlow},
  url     = {https://www.tensorflow.org/},
  urldate = {14/11/2019},
}

@online{GoogleTensorFlowLiteGuide:2020,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/lite/guide}},
  title   = {TensorFlow Lite Guide},
  year    = {2020},
  urldate = {31/03/2020},
}

@online{GoogleTensorFlowInstall:2019,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/install}},
  title   = {TensorFlow Installation},
  year    = {2020},
  urldate = {15/07/2020},
}


@online{GoogleTensorFlowLite:2019,
  editor  = {Google},
  year    = {2019},
  title   = {TensorFlow},
  url     = {https://www.tensorflow.org/lite},
  urldate = {14/11/2019},
}

@online{GoogleTensorFlowModel:2019,
  editor  = {Google},
  year    = {2019},
  title   = {TensorFlow models on the Edge TPU},
  url     = {https://coral.withgoogle.com/docs/edgetpu/models-intro/},
  urldate = {14/11/2019},
}


@online{TensorFlow.02.10.2020,
  editor   = {Google},
  year     = {2020},
  title    = {Training and evaluation with the built-in methods {\&}nbsp;|{\&}nbsp; TensorFlow Core},
  url      = {https://www.tensorflow.org/guide/keras/train_and_evaluate?hl=en},
  keywords = {TensorFlow, Keras, Training},
  urldate  = {29.10.2020}
}


@online{TensorFlow.02.12.2020b,
  abstract = {Eine durchg{\"a}ngige Open Source-Plattform f{\"u}r maschinelles Lernen f{\"u}r alle. Entdecken Sie das flexible {\"O}kosystem von TensorFlow mit Tools, Bibliotheken und Community-Ressourcen.},
  editor   = {Google},
  year     = {2020},
  title    = {TensorFlow},
  url      = {https://www.tensorflow.org/},
  urldate  = {03.12.2020}
}


@online{TensorFlow.10.09.2020,
  abstract = {Generates a {\&}lt;a href={\&}{\#}34;../../../tf/data/Dataset{\&}{\#}34;{\&}gt;{\&}lt;code{\&}gt;tf.data.Dataset{\&}lt;/code{\&}gt;{\&}lt;/a{\&}gt; from image files in a directory.},
  editor   = {Google},
  year     = {2020},
  title    = {tf.keras.preprocessing.image{\_}dataset{\_}from{\_}directory},
  url      = {https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory},
  urldate  = {11.11.2020}
}

@online{TensorFlow.14.12.2020,
  abstract = {Loads [CIFAR100 dataset](https://www.cs.toronto.edu/{\~{}}kriz/cifar.html).},
  editor   = {Google},
  year     = {2020},
  title    = {tf.keras.datasets.cifar100.load{\_}data},
  url      = {https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar100/load_data},
  urldate  = {17.12.2020}
}


@online{TensorFlow.18.08.2020,
  editor   = {Google},
  year     = {2020},
  title    = {Tutorials {\&}nbsp;|{\&}nbsp; TensorFlow Core},
  url      = {https://www.tensorflow.org/tutorials},
  keywords = {TensorFlow, Keras, Jupyter Notebook, Tutorial},
  urldate  = {29.10.2020}
}


@online{TensorFlow.30.10.2020,
  editor  = {Google},
  year    = {30.10.2020},
  title   = {Beginnen Sie mit TensorBoard},
  url     = {https://www.tensorflow.org/tensorboard/get_started},
  urldate = {04.12.2020}
}

@online{GoogleTensorFlowGPU:2020,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/install/gpu}},
  title   = {TensorFlow - GPU support},
  year    = {2020},
  urldate = {15/07/2020},
}

@online{GoogleTensorFlowExport:2020,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/tutorials/keras/save_and_load}},
  title   = {TensorFlow - Save and load models},
  year    = {2020},
  urldate = {10/09/2020},
}


@online{GoogleTensorFlowCNN:2020,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/tutorials/images/cnn}},
  title   = {TensorFlow - Convolutional Neural Network Example},
  year    = {2020},
  urldate = {10/09/2020},
}

@online{GoogleTensorFlowKerasSeq:2019,
  editor  = {Google},
  url     = {\url{https://www.tensorflow.org/api_docs/python/tf/keras/Sequential}},
  title   = {TensorFlow Keras Sequential Object},
  year    = {2020},
  urldate = {12/09/2020},
}

@online{GStreamer:2021,
  editor  = {{GStreamer}.org},
  year    = {2016},
  title   = {GStreamer},
  url     = {https://gstreamer.freedesktop.org/},
  urldate = {21/04/2021},
}

@online{TensorFlow.24.10.2020,
 editor   = {Google},
 year     = {2020},
 title    = {Python quickstart {\&}nbsp;|{\&}nbsp; TensorFlow Lite},
 url      = {https://www.tensorflow.org/lite/guide/python?hl=en},
 keywords = {Python, TensorFlow Lite interpreter},
 urldate  = {29.10.2020}
}

@online{Google.04.11.2020,
  editor = {Google},
  year = {04.11.2020},
  title = {TensorFlow Lite converter},
  url = {https://www.tensorflow.org/lite/convert},
  urldate = {16.01.2021}
}

@online{Google.09.10.2020,
  editor  = {Google},
  year    = {2020},
  title   = {Beginnen Sie mit TensorFlow Lite},
  url     = {https://www.tensorflow.org/lite/guide/get_started#1_choose_a_model},
  urldate = {12.12.2020}
}


@online{Google.13.01.2021,
  abstract = {Enum defining the optimizations to apply when generating tflite graphs.},
  author   = {TensorFlow},
  year     = {2021},
  title    = {tf.lite.Optimize},
  url      = {https://www.tensorflow.org/api_docs/python/tf/lite/Optimize},
  urldate  = {16.01.2021}
}

@online{Google.24.10.2020,
 editor   = {Google},
 year     = {2020},
 title    = {Python quickstart {\&}nbsp;|{\&}nbsp; TensorFlow Lite},
 url      = {https://www.tensorflow.org/lite/guide/python?hl=en},
 keywords = {Python, TensorFlow Lite interpreter},
 urldate  = {29.10.2020}
}


@online{Google.24.11.2020,
  editor  = {Google},
  year    = {24.11.2020},
  title   = {TensorFlow Lite inference},
  url     = {https://www.tensorflow.org/lite/guide/inference},
  urldate = {19.01.2021}
}


@online{Google.28.10.2020,
  editor  = {Google},
  year    = {2020},
  title   = {Installieren Sie TensorFlow 2},
  url     = {https://www.tensorflow.org/install},
  urldate = {29.11.2020}
}

@Article{Gu:2018,
  abstract = {In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.},
  author   = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and {Li Wang} and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
  date     = {22.12.2015},
  title    = {Recent Advances in Convolutional Neural Networks},
  url      = {http://arxiv.org/pdf/1512.07108v6},
  doi      = {10.1016/j.patcog.2017.10.013},
  journal  = {Pattern Recognition},
  volume   = 77,
  year     = 2018,
  pages    = {354--377},
  issn     = {0031-3203},
 keywords = {Add some keywords if you feel so inclined;Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning;Computer Science - Neural and Evolutionary Computing},
}

@Online{Gupta:2020b,
  abstract = {An introduction to activation functions. This article describes when to use which type of activation function and fundamentals of deep learning.},
  author   = {Gupta, Dishashree},
  year     = {2020},
  title    = {Activation Functions | Fundamentals Of Deep Learning},
  url      = {https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/},
  urldate  = {07.11.2020}
}

@Misc{Gupta:2020,
  title     = {Fundamentals of Deep Learning – Activation Functions and When to Use Them?},
  author    = {Gupta, Dishashree},
  year      = {2020},
  note      = {Eingesehen am 25.01.2020 [online]},
  url       = {https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/},
  publisher = {analyticsvidhya},
  key       = {Activation}
}

@article{Gysel:2016,
  author  = {Gysel, Philipp and Motamedi, Mohammad and Ghiasi, Soheil},
  journal = {arXiv preprint arXiv:1604.03168},
  title   = {Hardware-oriented approximation of convolutional neural networks},
  year    = {2016},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% H
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@INPROCEEDINGS{Halim:2019,
  author    = {Halim, Dareen K. and Ming, Tang Chong and Song, Ng Mow and Hartono, Dicky},
  booktitle = {2019 5th International Conference on New Media Studies (CONMEDIA)}, 
  title     = {Arduino-based IDE for Embedded Multi-processor System-on-Chip}, 
  year      = {2019},
  pages     = {135-138},
  doi       = {10.1109/CONMEDIA46929.2019.8981862}
}
	
@article{Hattersley:2019,
  title   = {Build a Teachable Machine with Coral's USB Accelerator},
  author  = {Hattersley, Lucy},
  journal = {The MagPi},
  volume  = 79,
  url     = {https://magpi.raspberrypi.org/articles/teachable-machine-coral-usb-accelerator},
}

@online{HDF5,
  publisher = {The HDF Group},
  year      = {1997},
  title     = {Hierarchical Data Format, version 5},
  url       = {http://www.hdfgroup.org/HDF5/},
}

@InProceedings{He:2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2016},
  note      = {\textcolor{blue}{\href{../../MLbib/CNN/He_Deep_Residual_Learning_CVPR_2016_paper.pdf}{[pdf]}}},  
  
}

@article{Heinze:2019,
  author  = {Heinze, Detlef},
  year    = {2019},
  title   = {Objekterkennung mit Pi-Kamera und Edge TPU},
  volume  = {3},
  journal = {Make},
}

@article{Heise:2020,
  year      = {2020},
  author    = {c't Redaktion (Autor)},
  title     = {c't Python-Projekte},
  isbn      = {978-3-95788-261-5},
  publisher = {Heise Zeitschriften Verlag},
  keywords  = {Python, TensorFlow, TensorFlow Lite},
}

@article{Heise:2020b,
  title    = {c't wissen Python 2020},
  journal  = {c't wissen},
  volume   = {3},
  year     = 2020,
  keywords = {Python, TensorFlow, TensorFlow Lite},
}

@Article{Hochreiter:1997,  
  author  = {Hochreiter, Sepp and Schmidhuber, Juergen},  
  journal = {Neural Computation},  
  title   = {Long Short-Term Memory},   
  year    = {1997},  
  volume  = {9},  
  number  = {8},  
  pages   = {1735-1780},  
  doi     = {10.1162/neco.1997.9.8.1735},
}

@Online{Howard:2017,
  abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
  author   = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  date     = {17.04.2017},
  title    = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision  Applications},
  url      = {http://arxiv.org/pdf/1704.04861v1},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note     = {\textcolor{blue}{\href{../../MLbib/CNN/MobileNets_Efficient_Convolutional_Neural_Networks.pdf}{[pdf]}}},  
}

@TechReport{Huang:2014,
  author      = {Huang, Gary B. and Learned-Miller,  Erik},
  title       = {Labeled Faces in the Wild: Updates and New Reporting Procedures},
  institution = {University of Massachusetts, Amherst},
  year        = 2014,
  number      = {UM-CS-2014-003},
  url         = {http://vis-www.cs.umass.edu/lfw/},
}
  
@article{Hubel:1981,
  author  = {Hubel, David H.},
  year    = {2018},
  title   = {Evolution  of  Ideas  on  the  Primary  Visual  Cortex,  1955-1978: A Biased Historical Account},
  journal = {Nobel lecture},
  url     = {https://www.nobelprize.org/uploads/2018/06/hubel-lecture.pdf},
}

@article{Hubel:1959,
  title   = {Receptive fields of single neurones in the cat's striate cortex},
  author  = {Hubel, David H. and Wiesel, Torsten N.},
  year    = 1959,
  volume  = 148, 
  number  = 3,
  journal = {The Journal of Physiology},
  pages   = {574--591},  
  doi     = {doi.org/10.1113/jphysiol.1959.sp006308},
}  

@manual{HuaweiKirin990:2020,
  editor = {Huawei Device Co., Ltd.},
  title  = {Huawei Kirin 990},
  year   = 2020,
  note   = {\url{https://consumer.huawei.com/en/campaign/kirin-990-series/}{Huawei Kirin 990}},
}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% I
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



@Online{ImageNet:2021,
  author    = {Fei-Fei, Li  and Deng, Jia and Russakovsky, Olga and Berg, Alex and Li, Kai},
  title     = {ImageNet},
  publisher = {Stanford Vision Lab}, 
  institute = {Stanford University, Princeton University  },
  url       = {https://www.image-net.org},
  date      = {15.05.2021},
  year      = 2021,
}  


@manual{IntelStickDataSheet:2019,
  editor = {{Intel Corporation}},
  year   = 2019,
  title  = "Intel Neural Compute Stick 2 - Data Sheet",
  url    = "https://ark.intel.com/content/www/de/de/ark/products/140109/intel-neural-compute-stick-2.html",
  note   = "\url{../IntelNCS2/ExterneDokumente/Intel/NCS2_Datasheet-English.pdf}{pdf}" 
}

@Misc{IntelNCSPi2,
  title   = {Intel\textsuperscript{\registered} Neural Compute Stick 2 und Open Source OpenVINO\textsuperscript{\trademark} Toolkit für raspbian * OS},
  year    = {29.07.2020},
  editor  = {{Intel Corporation}},
  url     = {https://www.intel.de/content/www/de/de/support/articles/000057005/boards-and-kits.html},
  urldate = {29.07.2020},
}

@Misc{IntelNCSPi,
  title   = {Raspberry Pi 4 and Intel® Neural Compute Stick 2 Setup},
  year    = {09.08.2019},
  editor  = {{Intel Corporation}},
  url     = {https://software.intel.com/content/www/us/en/develop/articles/raspberry-pi-4-and-intel-neural-compute-stick-2-setup.html},
  urldate = {09.08.2019},
}
 
@Misc{IntelMachineOperator,
  title   = {Create a Machine Operator Solution},
  year    = {18.12.2018},
  editor  = {{Intel Corporation}},
  url     = {https://software.intel.com/content/www/us/en/develop/topics/iot/reference-implementations/machine-operator-monitor.html},
  urldate = {18.12.2018},
}

@Misc{IntelMyriadVPU,
  title   = {Enhanced Visual Intelligence at the Network Edge},
  year    = {28.08.2017},
  editor  = {{Intel Corporation}},
  url     = {https://newsroom.intel.com/wp-content/uploads/sites/11/2017/08/movidius-myriad-xvpu-product-brief.pdf},
  urldate = {28.08.2017},
}

@Misc{Intel.31.07.2019,
  title   = {Product Brief - Intel Neural Compute Stick 2},
  year    = {31.07.2019},
  editor  = {{Intel Corporation}},
  url     = {https://www.intel.com/content/dam/support/us/en/documents/boardsandkits/neural-compute-sticks/NCS2_Product-Brief-English.pdf},
  urldate = {31.07.2019},
}

@Misc{IntelMovidiusSDKTools,
  title   = {Basic Installation and Configuration - Movidius SDK},
  year    = {11.10.2017},
  editor  = {{Intel Corporation}},
  url     = {https://movidius.github.io/ncsdk/install.html},
  urldate = {11.10.2017},
}

@Misc{IntelOneDAL,
  title   = {Intel® oneAPI Data Analytics Library},
  year    = {20.08.2015},
  editor  = {{Intel Corporation}},
  url     = {https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onedal.html},
  urldate = {20.08.2015},
}

@Misc{IntelMovidiusSDK,
  title   = {Intel Movidius Neural Compute SDK},
  year    = {15.06.2018},
  editor  = {{Intel Corporation}},
  url     = {https://movidius.github.io/ncsdk/tools/tools_overview.html},
  urldate = {15.06.2018},
}

@Misc{IntelMKL,
  title   = {Intel® oneAPI Math Kernel Library},
  year    = {11.09.2012},
  editor  = {{Intel Corporation}},
  url     = {https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html},
  urldate = {11.09.2012},
}

@Misc{IntelMKLVector,
  title   = {Intel® oneAPI Math Kernel Library Vector Mathematics Performance and Accuracy Data},
  year    = {04.12.2020},
  editor  = {{Intel Corporation}},
  url     = {https://software.intel.com/content/www/us/en/develop/documentation/onemkl-vmperfdata/top.html},
  urldate = {04.12.2020},
}

@Misc{IntelNCS2Chapter1,
  title   = {Introduction To Intel Neural Compute Stick 2 - Chapter 1},
  year    = {2020},
  editor  = {{Intel Corporation}},
  url     = {https://github.com/Wings-hub/201207IntelNCS2/blob/main/ExterneDokumente/Intel/IntelSchulung/IntelStick/Intel-Movidius-v01-Class1/Chapter%201%20-%20Introduction.pdf},
  urldate = {2020},
}
  
%https://github.com/movidius/ncappzoo


@InProceedings{Ide:2017,
  author    = {Ide, Hidenori and  Kurita, Takio},
  booktitle = {2017 International Joint Conference on Neural Networks ({IJCNN})},
  title     = {Improvement of learning for {CNN} with {ReLU} activation by sparse regularization},
  year      = {2017},
  month     = {may},
  publisher = {{IEEE}},
  doi       = {10.1109/ijcnn.2017.7966185},
}

@online{Intel:2018,
  author  = {Intel},
  url     = {\url{https://ark.intel.com/content/www/de/de/ark/products/190887/intel-core-i9-9900kf-processor-16m-cache-up-to-5-00-ghz.html}},
  title   = {Intel\textsuperscript{\textregistered} Core\textsuperscript{\texttrademark} i9 Prozessor 9900KF},
  year    = {2018},
  urldate = {24/02/2019},
}


@online{NCSDK:2019,
  title   = {NCSDK Documentation},
  version = {V2.10.01 2019-01-27},
  url     = {https://movidius.github.io/ncsdk/},
  editor  = {{Intel Corporation}},
  year    = 2019,
  date    = {28.06.2020}
}  

@online{IntelRequirements:2019,
  title   = {OpenVino - System Requirements},
  url     = {https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/system-requirements.html},
  editor  = {{Intel Corporation}},
  year    = 2019,
  date    = {28.06.2020}
}  

@online{IntelRelease:2020,
  title   = {Intel Distribution for Python - Release Notes and New Features},
  author  = {Liu, David and Greeneltch, Nathan G. and Venkatsch, Preethi},
  url     = {https://software.intel.com/content/www/us/en/develop/articles/intel-distribution-for-python-release-notes.html},
  editor  = {{Intel Corporation}},
  year    = 2020,
  date    = {16.07.2020}
}  



@Online{Iris:2021,
  author    = {Fisher, R. A.},
  title     = {Fisher's Iris Dataset},
  publisher = {Center for Machine Learning and Intelligent Systems},
  institute = {University of California, Irvine},
  url       = {https://archive.ics.uci.edu/ml/datasets/iris},
  date      = {15.05.2021},
  year      = 1936,
  note      = {\href{../../ExterneDokumente/Dataset/.pdf}{[pdf]}},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% J
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{Jain:2020,
  abstract      = {A growing number of applications implement predictive functions using deep learning models, which require heavy use of compute and memory. One popular technique for increasing resource efficiency is 8-bit integer quantization, in which 32-bit floating point numbers (fp32) are represented using shorter 8-bit integer numbers. Although deep learning frameworks such as TensorFlow, TFLite, MXNet, and PyTorch enable developers to quantize models with only a small drop in accuracy, they are not well suited to execute quantized models on a variety of hardware platforms. For example, TFLite is optimized to run inference on ARM CPU edge devices but it does not have efficient support for Intel CPUs and Nvidia GPUs. In this paper, we address the challenges of executing quantized deep learning models on diverse hardware platforms by proposing an augmented compiler approach. A deep learning compiler such as Apache TVM can enable the efficient execution of model from various frameworks on various targets. Many deep learning compilers today, however, are designed primarily for fp32 computation and cannot optimize a pre-quantized INT8 model. To address this issue, we created a new dialect called Quantized Neural Network (QNN) that extends the compiler's internal representation with a quantization context. With this quantization context, the compiler can generate efficient code for pre-quantized models on various hardware platforms. As implemented in Apache TVM, we observe that the QNN-augmented deep learning compiler achieves speedups of 2.35x, 2.15x, 1.35x and 1.40x on Intel Xeon Cascade Lake CPUs, Nvidia Tesla T4 GPUs, ARM Raspberry Pi3 and Pi4 respectively against well optimized fp32 execution, and comparable performance to the state-of-the-art framework-specific solutions.},
  author        = {Jain, Animesh and Bhattacharya, Shoubhik and Masuda, Masahiro and Sharma, Vin and Wang, Yida},
  date          = {18.06.2020},
  year          = 2020,
  title         = {Efficient Execution of Quantized Deep Learning Models: A Compiler  Approach},
  url           = {http://arxiv.org/pdf/2006.10226v1},
  keywords      = {Computer Science - Distributed Parallel and Cluster Computing;Computer Science - Learning;Computer Science - Programming Languages},
  eprint        = {2006.10226},
  archivePrefix = {arXiv},
  primaryClass  = {cs.DC},
  doi           = {arxiv-2006.10226},
}

@book{Janssen.2007,
  title     = {Statistische Datenanalyse mit SPSS für Windows},
  author    = {Janssen, Jürgen and Laatz, Wilfried},
  volume    = {6},
  year      = {2007},
  publisher = {Springer-Verlag}
}

@book{Jaworski:2019,
  author    = {Jaworski, Micha{\l} and Ziad{\'e}, Tarek},
  publisher = {Packt Publishing Ltd},
  title     = {Expert Python Programming: Become a master in Python by learning coding best practices and advanced programming concepts in Python 3.7},
  year      = {2019},
}

@book{Jaehne:2005,
  author    = {Jaehne, Bernd},
  year      = {2005},
  title     = {Digitale Bildverarbeitung },
  keywords  = {Ablauf einer Bildverarbeitung, Punktfeld, Bildsensor},
  address   = {Wiesbaden},
  edition   = {(6., überarbeitete und erweiterte Auflage)},
  publisher = {{Springer Vieweg}},
  note      = {\href{ExterneDokumente/Kreutzer-Sirrenberg2019_Chapter_WasVerstehtManUnterKünstlicher.pdf}{[pdf]}}
}

@online{JetsonHacks:2020,
	author  = {Jetsonhacks},
	year    = 2019,
	title   = {Jetson Nano GPIO},
	url     = {https://www.jetsonhacks.com/2019/06/07/jetson-nano-gpio/},
	urldate = {01/06/2020},
}

@article{Jin:2015,
  author   = {Jin, Xiaolong and Wah, Benjamin W.  and Cheng, Xueqi and Wang, Yuanzhuo},
  title    = {Significance and Challenges of Big Data Research},
  year     = {2015},
  journal  = {Big Data Research},
  volume   = 2,
  pages    = {59-64},
  doi      = {doi.org/10.1016/j.bdr.2015.01.006},
  keywords = {Big Data, Significance of big data, International initiatives on big data, Grand challenges of big data},
  note     = {\href{../../ExterneDokumente/BigData/1-s2.0-S2214579615000076-main.pdf}{[pdf]}},
}

@online{Junjie:2019,
  author = {Junjie, B. and Fang, L. and  Ke, Z. and al},
  title  = {ONNX: Opern Neural Network Exchange},
  year   = {2019},
  url    = {https://github.com/onnx/onnx},  
}

@online{Juschkat:2021,
  author  = {Katharina Juschkat},
  year    = {20.01.2021},
  title   = {Selbstlernender KI-Sensor und AIoT: Was Bosch auf der CES zeigt},
  url     = {https://www.industry-of-things.de/selbstlernender-ki-sensor-und-aiot-was-bosch-auf-der-ces-zeigt-a-991951/},
  urldate = {2021-04-16},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% K
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@book{Kaehler:2011,
  title     = {Statistische Datenanalyse: Verfahren verstehen und mit SPSS gekonnt einsetzen},
  author    = {Kähler, Wolf-Michael},
  volume    = {7},
  year      = {2011},
  publisher = {Springer-Verlag}
}

@article{kaggle.21.09.2020,
  abstract = {Explore and run machine learning code with Kaggle Notebooks | Using data from CIFAR-10 Python},
  author   = {Raj, Ananta},
  year     = {2020},
  title    = {AlexNet CNN Architecture on Tensorflow (beginner)},
  url      = {https://www.kaggle.com/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner},
  urldate  = {06.02.2021},
  editor   = {Kaggle},
}

@misc{KaggleIris:2018,
  publisher = {Kaggle},
  title     = {Iris Flower Dataset},
  url       = {https://www.kaggle.com/arshid/iris-flower-dataset},
  year      = 2018,
}  

@online{KDnuggets.07.12.2020,
  abstract = {Learn about the latest version of TensorFlow with this hands-on walk-through of implementing a classification problem with deep learning, how to plot it, and how to improve its results.},
  editor   = {KDnuggets},
  author   = {Anis, Ahmad},
  year     = {2020},
  title    = {Getting Started with TensorFlow 2},
  url      = {https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html},
  urldate  = {08.12.2020}
}

@online{KDnuggets.11.12.2020,
  abstract = {Tricks to improve TensorFlow training time with tf.data pipeline optimizations, mixed precision training and multi-GPU strategies.},
  author   = {Meude, Raphael},
  editor   = {KDnuggets},
  year     = {2020},
  title    = {TensorFlow 2.0 Tutorial: Optimizing Training Time Performance},
  url      = {https://www.kdnuggets.com/2020/03/tensorflow-optimizing-training-time-performance.html},
  urldate  = {12.12.2020}
}

@manual{Kendryte:2019,
  title     = {K210 Guide},
  editor    = {Kendryte Canaan Inc},
  year      = {2019},
  publisher = {Canaan Inc.},
  url       = {http://kendryte-docs.s3-website.cn-north-1.amazonaws.com.cn/docs/standalone_programming_guide/en/},
  urldate   = {01.06.2021},
}

@online{Keras:2020,
  editor  = {Keras SIG},
  year    = {2020},
  title   = {Keras},
  url     = {https://keras.io/},
  urldate = {24/07/2020},
}

@online{Keras:2020b,
  editor  = {Keras SIG},
  url     = {\url{https://keras.io/api/layers/core_layers/dense/}},
  title   = {Keras Dense Layer},
  year    = {2020},
  urldate = {08/05/2020},
}

@article{Khan:2020,
  author   = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
  year     = 2020,
  title    = {A survey of the recent architectures of deep convolutional neural networks},
  journal  = {Artificial Intelligence Review},
  number   = 5455,
  volume   = 53,
  abstract = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
  doi      = {https://doi.org/10.1007/s10462-020-09825-6},
  note    = {\textcolor{blue}{\href{../../MLbib/CNN/1901.06032.pdf}{[pdf]}}},
}


@online{Kobylinska:2020,
  author  = {{Kobylinska, Anna and Martins, Filipe, and Ostler, Ulrike}},
  year    = {2020},
  title   = {Was ist FPGA - Field Programmable Gate Array?},
  url     = {https://www.datacenter-insider.de/was-ist-fpga--field-programmable-gate-array-a-955142/},
  urldate = {2021-04-13},
}

@book{Kononenko:2007,
 year = {2007},
 title = {Machine Learning and Data Mining},
 keywords = {ML, Data Mining, KDD, Neural Networks},
 publisher = {{Woodhead Publishing}},
 isbn = {978-1-904275-21-3},
 editor = {Kononenko, Igor and Kukar, Matja{\v{z}}},
}

@Inbook{Koziol:2011,
  author    = {Koziol, Quincey},
  editor    = {Padua, David},
  title     = {HDF5},
  bookTitle = {Encyclopedia of Parallel Computing},
  year      = {2011},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {827--833},
  isbn      = {978-0-387-09766-4},
  doi       = {10.1007/978-0-387-09766-4_44},
  url       = {https://doi.org/10.1007/978-0-387-09766-4_44},
}


@book{Kreutzer:2020,
  author    = {Kreutzer, Ralf T. and Sirrenberg Marie},
  year      = {2020},
  title     = {{Künstliche Intelligenz verstehen, Grundlagen - Use-Cases - unternehmenseigene KI-Journey}},
  keywords  = {Künstliche Intelligenz, Bilderkennung, Maschinen-Lernen, Algorithmus, neuronales Netzwerk},
  address   = {Wiesbaden},
  edition   = {1.},
  publisher = {Springer Vieweg},
  note      = {\textcolor{blue}{\href{ExterneDokumente/Kreutzer-Sirrenberg2019_Chapter_WasVerstehtManUnterKünstlicher.pdf}{[pdf]}}}, 
  url		= {https://link.springer.com/content/pdf/10.1007%2F978-3-658-25561-9_1.pdf},
}

@Misc{Kriesel:2008,
  title  = {Ein kleiner {\"u}berblick {\"u}ber Neuronale Netze},
  author = {Kriesel, David},
  year   = {2008},
  note   = {Eingesehen am 28.12.2019 [online]},
  url    = {http://www.dkriesel.com/index.php},
  key    = {Neuronale Netze}
}

@online{Krizhevsky:2009,
 author  = {Krizhevsky, Alex},
 year    = 2009,
 date    = {2009},
 title   = {Learning Multiple Layers of Features from Tiny Images},
 url     = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
 urldate = {17.12.2020},
}

@InProceedings{Krizhevsky:2012,
  abstract  = {Neural Information Processing Systems http://nips.cc/},
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Pereira, F. and Burges, C. J. C.  and Bottou, L. and Weinberger, K. Q.},
  pages     = {1097--1105},
  publisher = {Curran Associates, Inc.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  url       = {proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  volume    = {25},
  year      = {2012},
  doi       = {0.1145/3065386},
}


@online{Krizhevsky:2017,
  author    = {Krizhevsky, Alex and Nair, V. and Hinton, G.},
  year      = {2017},
  publisher = {Canadian Institute for Advanced Research},
  title     = {CIFAR-10 and CIFAR-100 datasets},
  url       = {https://www.cs.toronto.edu/~kriz/cifar.html},
  urldate   = {17.12.2020}
}

@article{Krizhevsky:2012b,
  author  = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey},
  year    = {2012},
  month   = {01},
  pages   = {},
  title   = {ImageNet Classification with Deep Convolutional Neural Networks},
  volume  = {25},
  journal = {Neural Information Processing Systems},
  doi     = {10.1145/3065386},
  url     = {http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf},
}

@book{Kruse:2015,
  author    = {Kruse, Rudolf and Borgelt, Christian and Braune, Christian and Klawonn, Frank and Moewes, Christian and Steinbrecher, Matthias},
  year      = {2015},
  title     = {Computational Intelligence},
  address   = {Wiesbaden},
  publisher = {{Springer Fachmedien Wiesbaden}},
  isbn      = {978-3-658-10903-5},
  doi       = {10.1007/978-3-658-10904-2},
}

@InProceedings{Kurbanov2019RecognitionOF,
  author = {Kurbanov, Eldar},
  title  = {Recognition of Faces, Head Positions, Gender, Age, and Emotions In Real Time Using Deep Convolutional Neural Networks},
  year   = {2019},
}

@Book{Kurniawan:2021,
  author    = {Kurniawan, Agus},
  title     = {IoT Projects with NVIDIA Jetson Nano: AI-Enabled Internet of Things Projects for Beginners},
  year      = {2021},
  publisher = {Apress},
  address   = {Berkeley, CA},
  abstract  = {NVIDIA Jetson Nano is an NVIDIA product that can implement IoT solutions with the power of GPU computation. This board has GPIO pins and a GPU core to help developers, makers, and IT users build programs easily. In this chapter, we will get a brief introduction to NVIDIA Jetson Nano.},
  isbn      = {978-1-4842-6452-2},
  doi       = {10.1007/978-1-4842-6452-2_1},
  url       = {https://doi.org/10.1007/978-1-4842-6452-2_1},
}

@article{Kurgan:2006,
  abstract = {The Knowledge Engineering Review},
  author   = {Kurgan, Lukasz A. and Musilek, Petr},
  year     = {2006},
  title    = {A survey of Knowledge Discovery and Data Mining process models},
  pages    = {1--24},
  volume   = {21},
  number   = {1},
  issn     = {0269-8889},
  journal  = {The Knowledge Engineering Review},
  doi      = {10.1017/S0269888906000737},
}

@article{Kwapisz:2011,
  title   = {Activity recognition using cell phone accelerometers},
  author  = {Kwapisz, Jennifer R.  and Weiss, G. and Moore, Samuel},
  journal = {SIGKDD Explor.},
  year    = {2011},
  volume  = {12},
  pages   = {74-82}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% L
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{LambdaLabs:2019,
  editor  = {{Lambda Labs}},
  url     = {{https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks}},
  title   = {RTX 2080 Ti Deep Learning Benchmarks with TensorFlow},
  year    = {2019},
  urldate = {04/03/2019},
}

@article{LeCun:1998,
  author  = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal = {Proceedings of the IEEE}, 
  title   = {Gradient-based learning applied to document recognition}, 
  year    = {1998},
  volume  = {86},
  number  = {11},
  pages   = {2278--2324},
  doi     = {10.1109/5.726791},
}

@online{LeCun:2013,
  author  = {LeCun, Yann and Cortes, Corinna and Burges, Chris},
  year    = {2013},
  title   = {MNIST handwritten digit database},
  url     = {http://yann.lecun.com/exdb/mnist/},
  urldate = {04.12.2020}
}

@online{Leibson:2018,
  author = {{Leibson, Steve}},
  year   = 2018,
  title  = {Use IMUs for Precise Location Data When GPS Won’t Suffice},
  date   = {24.06.2021},
  url    = {https://www.digikey.ch/de/articles/use-imus-for-precise-location-data-when-gps-wont-suffice},
}

@online{Leibson:2019,
  author = {{Leibson, Steve}},
  year   = 2019,
  title  = {IMUs zur exakten Standortbestimmung: Teil 2 – h"ohere Praezision durch IMU-Software},
  date   = {24.01.2019},
  url    = {https://www.digikey.ch/de/articles/imus-for-precise-location-part-2-how-to-use-imu-software-for-greater-precision},
}

@misc{Lemaitre:2017,
  title  = {Over-sampling},
  author = {Lemaitre, G. and Nogueira, F. and Oliveira, D. and Aridas, C.} ,
  year   = {2017},
  note   = {Eingesehen am 29.12.2019 [online]},
  url    = {https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html},
  key    = {random-oversampling}
}

@article{Li:2007,
  author  = {Li, Tianrui and {Da Ruan}},
  year    = {2007},
  title   = {An extended process model of knowledge discovery in database},
  pages   = {169--177},
  volume  = {20},
  number  = {2},
  issn    = {1741-0398},
  journal = {Journal of Enterprise Information Management},
  doi     = {10.1108/17410390710725751},
}

@article{Lin:2014,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {The Computing Research Repository (CoRR)},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Lindholm:2008,
  author    = {Lindholm, Erik  and Nickolls, John  and  Oberman, Stuart and Montrym, John },
  journal   = {{IEEE} Micro},
  title     = {{NVIDIA} Tesla: A Unified Graphics and Computing Architecture},
  year      = {2008},
  month     = {mar},
  number    = {2},
  pages     = {39--55},
  volume    = {28},
  doi       = {10.1109/mm.2008.31},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@INPROCEEDINGS{Liu:2020,
  author    = {Liu, Zhe-Ting and Wong, Davy P. Y. and Chou, Pai H.},
  booktitle = {2020 International Symposium on VLSI Design, Automation and Test (VLSI-DAT)}, 
  title     = {An Imu-Based Wearable Ring For On-Surface Handwriting Recognition}, 
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-4},
  doi       = {10.1109/VLSI-DAT49148.2020.9196479}
}

@article{LopezdeLacalle:2020,
  author = {{L{\'o}pez de Lacalle, Luis Norberto} and Posada, Jorge},
  year   = {2020},
  title  = {New Industry 4.0 Advances in Industrial IoT and Visual Computing for Manufacturing Processes},
}

@Article{Lu:2019,
  author  = {Lu, Yu and Xie, Shanjuan and Wu, Shiqian},
  year    = {2019},
  month   = {03},
  pages   = {1-1},
  title   = {Exploring Competitive Features Using Deep Convolutional Neural Network for Finger Vein Recognition},
  volume  = {PP},
  journal = {IEEE Access},
  doi     = {10.1109/ACCESS.2019.2902429},
  note    = {\textcolor{blue}{\href{../../MLbib/CNN/08663285.pdf}{[pdf]}}},
}


@online{Luber:2019,
  author  = {Luber, Stefan and Litzel, Nico},
  year    = {2019},  
  title   = {{Was ist ein Convolutional Neural Network?}},
  url     = {https://www.bigdata-insider.de/was-ist-ein-convolutional-neural-network-a-801246/},
  urldate = {2021-06-01},
}


@InProceedings{Luebke:2008,
  author    = {Luebke, David},
  booktitle = {2008 5\textsuperscript{th} {IEEE} International Symposium on Biomedical Imaging: From Nano to Macro},
  title     = {{CUDA}: Scalable parallel programming for high-performance scientific computing},
  year      = {2008},
  month     = {may},
  publisher = {{IEEE}},
  doi       = {10.1109/isbi.2008.4541126},
}

@online{Lundh:2015,
  title  = {Image file formats},
  author = {Lundh, Fredrik and Clark, Alex},
  year   = {2015},
  note   = {Eingesehen am 17.12.2019 [online]},
  url    = {https://pillow.readthedocs.io/en/3.0.x/handbook/image-file-formats.html}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% M
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{M5Stack:2021Camera,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{M5Camera}},
  url     =  {https://docs.m5stack.com/en/unit/m5camera},
  urldate = {2021-06-16},
}

@online{M5Stack:2021CameraX,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{M5CameraX}},
  url     = {https://docs.m5stack.com/en/unit/m5camera_x},
  urldate = {2021-06-16},
}

@online{M5Stack:2021CameraF,
  author  = {M5Stack},
  year    = {2021},  
  title   = {{M5CameraF}},
  url     = {https://docs.m5stack.com/en/unit/m5camera_f},
  urldate = {2021-06-16},
}

@online{M5StackMiPy,
	author  = {M5Stack},
	year    = {2021},  
	title   = {M5StackMicroPython},
	url     = {https://docs.m5stack.com/#/en/quick_start/m5core/m5stack_core_get_started_MicroPython},
	urldate = {2021-04-17},}

@online{M5Start,
	author  = {Nurgaliyev Shakhizat},
	year    = {2019},  
	title   = {Getting Started with the M5StickV AI + IOT Camera},
	url     = {https://m5stack.hackster.io/shahizat005/getting-started-with-the-m5stickv-ai-iot-camera-d92d42},
	urldate = {2021-04-17},}

@online{M5Stick,
	author  = {M5Stack},
	year    = {2021},  
	title   = {M5Stick},
	url     = {https://docs.m5stack.com/#/en/core/m5stick},
	urldate = {2021-04-17},}

@online{M5StickC,
	author  = {M5Stack},
	year    = {2021},  
	title   = {M5StickC},
	url     = {https://docs.m5stack.com/#/en/core/m5stickc},
	urldate = {2021-04-17},}

@online{M5StickCplus,
	author  = {M5Stack},
	year    = {2021},  
	title   = {M5StickCplus},
	url     = {https://docs.m5stack.com/#/en/core/m5stickc_plus},
	urldate = {2021-04-17},}

@online{M5StickT,
	author  = {M5Stack},
	year    = {2021},  
	title   = {M5StickT},
	url     = {https://docs.m5stack.com/#/en/core/m5stickt},
	urldate = {2021-04-17},}

@online{M5StickV-Diebstahl,
	author  = {anoY'an},
	year    = {2019},  
	title   = {PuddingAlert-V},
	url     = {https://m5stack.hackster.io/anoken2017/puddingalert-v-34c560},
	urldate = {2021-06-16},}

@online{M5StickV-SocialDistancing,
	author  = {RuVic saballa},
	year    = {2020},  
	title   = {Mobile Social Distancing using Face detection (M5stickV)},
	url     = {https://m5stack.hackster.io/ruvic101/mobile-social-distancing-using-face-detection-m5stickv-4315cd},
	urldate = {2021-06-16},}

@online{M5StickV-Sitzhaltung,
  author  = {Katsu Shun},
  year    = {2019},  
  title   = {Bad Pose Detector using M5StickV},
  url     = {https://m5stack.hackster.io/katsushun89/bad-pose-detector-using-m5stickv-62e57b#toc-results-6},
  urldate = {2021-06-16},
}

@online{M5Stack:2021ESP32CAM,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{ESP32CAM}},
  url     = {https://docs.m5stack.com/en/unit/esp32cam},
  urldate = {2021-06-16},
}

@online{M5StickVÜbersicht,
	author  = {M5Stack},
	title   = {M5StickV},
	url     = {https://docs.m5stack.com/#/en/core/m5stickv},
	urldate = {2021-04-13},}

@online{M5StackStore:2021,
	editot  = {M5Stack},
	year    = {2021},  
	title   = {M5StickV K210 AI Camera (Without Wifi)},
	url     = {https://m5stack-store.myshopify.com/products/stickv},
	urldate = {2021-04-17},}


@online{M5StackTraining:2021,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {V-Training},
  url     = {https://docs.m5stack.com/#/en/related_documents/v-training},
  urldate = {2021-04-17},
}

@online{M5Stack:2021V2,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{UnitV2}},
  url     = {https://docs.m5stack.com/en/unit/unitv2},
  urldate = {2021-06-16},
} 

@online{M5Stack:2021V2Function,
  author  = {M5Stack},
  year    = {2021},  
  title   = {{UnitV2 recognition service}},
  url     = {https://docs.m5stack.com/en/quick_start/unitv2/base_functions},
  urldate = {2021-06-16},
}


@online{M5Stack:2021V2Training,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{V-Training}},
  url     = {https://docs.m5stack.com/en/quick_start/unitv2/v_training},
  urldate = {2021-06-16},
}  

@online{M5Stack:2021V2640,
  author  = {M5Stack},
  year    = {2021},  
  title   = {{UnitV OV2640}},
  url     = {https://docs.m5stack.com/en/unit/unitv},
  urldate = {2021-06-16},
} 


@online{M5Stack:2021V7740,
  editor  = {M5Stack},
  year    = {2021},  
  title   = {{UnitV OV7740}},
  url     = {https://docs.m5stack.com/en/unit/unitv_ov7740},
  urldate = {2021-06-16},
}

@online{M5Stack:2021VFunction,
	editor  = {M5Stack},
	year    = {2021},  
	title   = {{V-Function}},
	url     = {https://docs.m5stack.com/en/quick_start/unitv/v_function},
	urldate = {2021-06-16},}


@online{M5Stick:2021,
  editor  = {M5Stack},
  title   = {M5StickV},
  url     = {https://docs.m5stack.com/#/en/core/m5stickv},
  urldate = {2021-04-13},
}


@book{Maimon:2010,
  author    = {Maimon, Oded and Rokach, Lior},
  year      = {2010},
  title     = {Data Mining and Knowledge Discovery Handbook},
  address   = {Boston, MA},
  publisher = {{Springer US}},
  isbn      = {978-0-387-09822-7},
  doi       = {10.1007/978-0-387-09823-4},
}

@InProceedings{Manning2020,
  author    = {Manning, Derek and  Li, Peilong and  Wu, Xiaoban and  Luo, Yan and  Zhang, Tong and  Li, Weigang},
  booktitle = {{ICC} 2020 - 2020 {IEEE} International Conference on Communications ({ICC})},
  title     = {{ACETA}: Accelerating Encrypted Traffic Analytics on Network Edge},
  year      = {2020},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/icc40277.2020.9148798},
}

@InProceedings{Malakhov2016,
  author    = {Malakhov, Anton},
  booktitle = {Proceedings of the 15th Python in Science Conference},
  title     = {Composable Multi-Threading for Python Libraries},
  year      = {2016},
  publisher = {{SciPy}},
  doi       = {10.25080/majora-629e541a-002},
}

@InProceedings{Malakhov2018,
  author    = {Malakhov, Anton  and Liu, David  and Gorshkov, Anton  and Wilmarth, Terry},
  booktitle = {Proceedings of the 17th Python in Science Conference},
  title     = {Composable Multi-Threading and Multi-Processing for Numeric Libraries},
  year      = {2018},
  publisher = {{SciPy}},
  doi       = {10.25080/majora-4af1f417-003},
}

@InProceedings{Mark:2003,
  author    = {Mark, William R. and  Glanville, R. Steven and  Akeley, Kurt and Kilgard, Mark J.},
  booktitle = {{ACM} {SIGGRAPH} 2003 Papers on - {SIGGRAPH} {\textquotesingle}03},
  title     = {Cg: a system for programming graphics hardware in a C-like language},
  year      = {2003},
  publisher = {{ACM} Press},
  doi       = {10.1145/1201775.882362},
}

@Online{Martins:2019,
  title  = {Was bedeutet Edge Computing?},
  author = {Martins, Filipe  and Kobylinska, Anna},
  year   = {2019},
  note   = {Eingesehen am 18.12.2019 [online]},
  url    = {https://www.industry-of-things.de/was-bedeutet-edge-computing-a-678225/},
  key    = {IoT}
}


@misc{MaximIntegrated:2019,
  title     = {MAX98357A/MAX98357B - Tiny, Low-Cost, PCM Class D Amplifier with  Class AB Performance },
  editor    = {Maxim Integrated},
  year      = {2019},
  publisher = {Maxim Integrated},
  url       = {https://datasheets.maximintegrated.com/en/ds/MAX98357A-MAX98357B.pdf},
  urldate   = {2021-06-10},
}

@article{McCarthy:2006,
  author  = {McCarthy, J. and  Minsky, M. L. and  Rochester, N. and Shannon, C. E.},
  year    = 2006,
  title   = {A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955},
  journal = {AI Magazine},
  volume  = 27,
  number  = 4, 
  doi     = {doi.org/10.1609/aimag.v27i4.1904},
}  

@inproceedings{McKinsey:2017,
  title     = {Smartening up with Artificial Intelligence (AI) - What's in it for Germany and its Industrial Sector?},
  publisher = {McKinsey \& Company},
  year      = {2017},
}

@article{McCulloch:1943,
  abstract = {Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  author   = {McCulloch, Warren S. and Pitts, Walter},
  year     = {1943},
  title    = {A logical calculus of the ideas immanent in nervous activity},
  pages    = {115--133},
  volume   = {5},
  number   = {4},
  issn     = {1522-9602},
  journal  = {The bulletin of mathematical biophysics},
  doi      = {10.1007/BF02478259}
}

@online{Meel:2021,
  author  = {Meel, Vidushi},
  year    = {2021},
  title   = {YOLOv3: Echtzeit-Objekterkennungsalgorithmus},
  url     = {https://viso.ai/deep-learning/yolov3-overview/ },
  urldate = {2021-06-15},	
}

@InProceedings{Memeti:2017,
  author    = {Memeti, Suejb and Li, Lu  and  Pllana, Sabri and  Ko{\l}odziej, Joanna and  Kessler, Christoph},
  booktitle = {Proceedings of the 2017 Workshop on Adaptive Resource Management and Scheduling for Cloud Computing - {ARMS}-{CC} {\textquotesingle}17},
  title     = {Benchmarking {OpenCL}, {OpenACC}, {OpenMP}, and {CUDA}},
  year      = {2017},
  publisher = {{ACM} Press},
  doi       = {10.1145/3110355.3110356},
}

@article{Merkert:2020,
  author    = {Merkert, Pina},
  title     = {8-Bit-KI mit  TensorFlow-Lite},
  year      = 2020,
  publisher = {Heise Medien GmbH \& Co. KG},
  journal   = {c't Python-Projekte},
  pages     = {78--83},
  note      = "\href{../../ExterneDokumente/Python/ctPythonSonderheft2020.pdf}{pdf}" 
}


@article{Michel:2018,
  author    = {Michel, Thibaud and  Geneves, Pierre and	 Fourati, Hassen and 	NabilLayaida, 	Nabil},
  title     = {Attitude estimation for indoor navigation and augmented reality with smartphones},
  journal   = {Pervasive Mob. Comput.},
  volume    = {46},
  pages     = {96--121},
  year      = {2018},
  url       = {https://doi.org/10.1016/j.pmcj.2018.03.004},
  doi       = {10.1016/j.pmcj.2018.03.004},
  timestamp = {Sat, 22 Feb 2020 19:17:55 +0100},
  biburl    = {https://dblp.org/rec/journals/percom/MichelGFL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}


@book{Michelucci:2019,
  author    = {Michelucci, Umberto},
  year      = {2019},
  title     = {Advanced Applied Deep Learning},
  address   = {Berkeley, CA},
  publisher = {Apress},
  isbn      = {978-1-4842-4975-8},
  doi       = {10.1007/978-1-4842-4976-5},
}
 
@Misc{MLnotebook:2017,
  title  = {Convolutional Neural Networks - Basics},
  author = {MLnotebook},
  year   = {2017},
  note   = {Eingesehen am 15.01.2020 [online]},
  url    = {https://mlnotebook.github.io/post/CNN1/}
}
 
@misc{csi2:2019,
  publisher = {Mobile Industry Processor Interface (MIPI) Alliance},
  title     = {MIPI Camera Serial Interface 2 (MIPI CSI-2)},
  version   = {3.0},
  url       = {https://www.mipi.org/specifications/csi-3},
  year      = 2019,
}
  
@misc{csi2:2018,  
  title     = {Die Bedeutung der MIPI CSI-2-Schnittstelle für Embedded Vision Anwendungen},
  publisher = {Basler AG},
  url       = {https://www.baslerweb.com/de/vertrieb-support/downloads/downloads-dokumente/die-bedeutung-der-mipi-csi-2-schnittstelle-fuer-embedded-vision-anwendungen/},
  note      = {\textcolor{blue}{\href{../../MLbib/RaspCam/BAS1710_White_Paper_MIPI_web.pdf}{[pdf]}}},
  year      = 2018,
}
 

@book{Mitescu:2005,
  abstract  = {Stressing common characteristics and real applications of the most used microcontrollers, this practical guide provides readers with hands-on knowledge of how to implement three families of microcontrollers (HC11, AVR, and 8051). Unlike the rest of the ocean of literature on individual chips, Microcontrollers in Practice supplies side-by-side comparisons and an overview that treats the systems as resources available for implementation. Packed with hundreds of practical examples and exercises to foster mastery of concepts and details, the guide also includes several extended projects. By treating the less expensive 8-bit and RISC microcontrollers, this information-dense manual equips students and home-experimenters with the know-how to put these devices into operation.},
  author    = {Mitescu, Marian and Susnea, Ioan},
  year      = {2005},
  title     = {Microcontrollers in practice},
  url       = {http://site.ebrary.com/lib/alltitles/docDetail.action?docID=10143800},
  address   = {Berlin and Heidelberg},
  volume    = {18},
  publisher = {Springer},
  isbn      = {9783540283089},
  series    = {Springer series in advanced microelectronics},
  doi       = {10.1007/3-540-28308-0},
}

@Online{Moeser:2018,
  abstract = {Ein neuronales Netz (seltener auch neurales Netz) ist eine Ansammlung von einzelnen Informationsverarbeitungseinheiten (Neuronen), die schichtweise in einer Netzarchitektur angeordnet sind. Im Zusammenhang mit k{\"u}nstlicher Intelligenz spricht man von{\&}nbsp;k{\"u}nstlichen neuronalen Netzen.},
  author   = {Moeser, Julian},
  year     = {2018},
  title    = {K{\"u}nstliche neuronale Netze - Aufbau {\&} Funktionsweise},
  url      = {https://jaai.de/kuenstliche-neuronale-netze-aufbau-funktion-291/},
  urldate  = {05.11.2020}
}

@Misc{Moeser:2019,
  title  = {K{\"u}nstliche neuronale Netze – Aufbau und Funktionsweise},
  author = {Moeser, Julian},
  year   = {2019},
  note   = {Eingesehen am 09.02.2020 [online]},
  url    = {https://jaai.de/kuenstliche-neuronale-netze-aufbau-funktion-291/},
  key    = {KIAufbau}
}

@book{Monk:2017,
  author    = {Monk, Simon},
  title     = {Raspberry Pi Kochbuch},
  year      = 2017,
  publisher = "O'Reilly",
  address   = {Heidelberg}
}  

@Article{Munson:1996,
    author  = {D. C. {Munson}},
    journal = {IEEE Transactions on Image Processing}, 
    title   = {A note on Lena}, 
    year    = {1996},
    volume  = {5},
    number  = {1},
    pages   = {3--3},
    doi     = {10.1109/TIP.1996.8100841},
}

@online{MXNet:2020,
  year    = {2020},
  title   = {MXNet},
  editor  = {Apache Software Foundation Apache MXNet},
  url     = {https://mxnet.apache.org/},
  urldate = {24/07/2020},
}

@article{MobileNet:2017,
  author        = {{Howard}, Andrew G. and {Zhu}, Menglong and {Chen}, Bo and
                   {Kalenichenko}, Dmitry and {Wang}, Weijun and {Weyand}, Tobias and
                   {Andreetto}, Marco and {Adam}, Hartwig},
  title         = "{MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}",
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  year          = "2017",
  month         = "Apr",
  eid           = {arXiv:1704.04861},
  pages         = {arXiv:1704.04861},
  archivePrefix = {arXiv},
  eprint        = {1704.04861},
  primaryClass  = {cs.CV},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2017arXiv170404861H},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@online{MovidiusAppZoo:2019,
  title  = {Movidius App  Zoo},
  editor = {{Intel Corporation}},
  year   = 2019,
  url    = "https://github.com/movidius/ncappzoo",
  note   = {\textcolor{blue}{\href{../IntelNCS2/ExterneDokumente/Intel/NCS2_Datasheet-English.pdf}{[pdf]}}},
  date   = {26.06.2020},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% N
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Namatevs.2017,
  author  = {Namat vs, Ivars},
  year    = {2017},
  title   = {Deep Convolutional Neural Networks: Structure, Feature Extraction and Training},
  volume  = {20},
  number  = {1},
  journal = {Information Technology and Management Science},
  doi     = {10.1515/itms-2017-0007},
  file    = {Deep_Convolutional_Neural_Networks_Structure_Featu:C\:\\Users\\chris\\Desktop\\EP\\Master\\3. Semester\\Projekt\\200915JetsonNano\\Citavi\\KI mit Jetson Nano\\Citavi Attachments\\Deep_Convolutional_Neural_Networks_Structure_Featu.pdf:pdf}
}

@INPROCEEDINGS{Nayyar:2016,
  author    = {Nayyar, Anand and Puri, Vikram},
  booktitle = {2016 3\textsuperscript{rd} International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title     = {A review of Arduino board's, Lilypad's   Arduino shields}, 
  year      = {2016},
  volume    = {10},
  number    = {},
  pages     = {1485-1492},
  isbn      = {9781467394178},
  doi       = {}
}


@online{GitHubGPIO:2020,
	author  = "NVIDIA",
	year    = {2020},
	title   = {jetson-gpio},
	url     = {https://github.com/NVIDIA/jetson-gpio},
	urldate = {01/06/2020},
}

@book{Nielsen:2015,
  author    = {Nielsen, Michael A.},
  year      = {2015},
  title     = {Neural Networks and Deep Learning},
  url       = {http://neuralnetworksanddeeplearning.com/chap1.html},
  publisher = {{Determination Press}}
}

@article{Nwankpa:2018,
  author      = {Nwankpa, Chigozie  and  Ijomah, Winifred and Gachagan, Anthony  and Marshall, Stephen },
  title       = {Activation Functions: Comparison of trends in Practice and Research for Deep Learning},
  abstract    = {Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.},
  date        = {2018-11-08},
  eprint      = {1811.03378},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  url         = {https://arxiv.org/pdf/1811.03378v1.pdf},
  keywords    = {cs.LG, cs.CV},
}

@Article{Nickolls:2008,
  author    = {Nickolls, John and  Buck, Ian and  Garland, Michael and  Skadron, Kevin},
  journal   = {Queue},
  title     = {Scalable Parallel Programming with {CUDA}},
  year      = {2008},
  month     = {mar},
  number    = {2},
  pages     = {40--53},
  volume    = {6},
  doi       = {10.1145/1365490.1365500},
  publisher = {Association for Computing Machinery ({ACM})},
}

@online{Nordic:2021,
  editor    = {{Nordic Semiconductor}},
  year      = 2021,
  ALTauthor = {Nordic},
  ALTeditor = {Nordic},
  title     = {nRF52840 - System-on-Chip},
  date      = {03.05.2021},
  url       = {https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840},
}

@online{Numpy:2021,
  editor = {{The NumPy community}},
  year   = 2021,
  title  = {What is NumPy?},
  date   = {20.06.2021},
  url    = {https://numpy.org/doc/stable/user/whatisnumpy.html},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% O
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{OmniVision:2014,
  title     = {OV7740/OV7241VGA Ultra-High Sensitivity CMOS Image Sensor product brief },
  editor    = {OmniVision Technologies, Inc.},
  year      = {2014},
  publisher = {OmniVision Technologies, Inc.},
  url       = {https://www.ovt.com/sensors/OV7740}
}

@online{Onnx:2021,
  publisher = {ONNX Runtime Developers}, 
  title     = {ONNX Runtime},
  year      = {2021},
  url       = {https://onnxruntime.ai/}  
}

@online{OpenNN:2020,
  year    = {2020},
  title   = {OpenNN},
  editor  = {Artificial Intelligence Techniques, Ltd},
  url     = {https://www.opennn.net/},
  urldate = {24/07/2020},
}

@Misc{OpenCV:2020,
  title  = {OpenCV},
  editor = {Wikipedia},
  year   = {2020},
  note   = {Eingesehen am 16.12.2019 [online]},
  url    = {https://de.wikipedia.org/wiki/OpenCV},
  key    = {OpenCV}
}

@online{OpenCV:2020b,
  year    = {2020},
  title   = {OpenCV},
  editor  = {OpenCV Team},
  url     = {https://opencv.org/},
  urldate = {24/07/2020},
}

@online{OpenVino:2020,
  year    = {2020},
  title   = {OpenVino},
  editor  = {OpenOpenVino:2020ino Team},
  url     = {https://www.openvino.org/},
  urldate = {24/07/2020},
}

@Misc{OpenVINO.installRaspbian,
  title   = {Install OpenVINO\textsuperscript{\texttrademark} toolkit for Raspbian* OS},
  year    = {03.04.2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_raspbian.html},
  urldate = {03.04.2019},
}

@Misc{OpenVINO.gettingStartedRaspbian,
  title   = {Get Started with OpenVINO\textsuperscript{\texttrademark} Toolkit on Raspbian* OS},
  year    = {2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/latest/openvino_docs_get_started_get_started_raspbian.html},
  urldate = {2019},
}

@Misc{OpenVINO.ActionRecog,
  title   = {Action Recognition Python Demo},
  year    = {29.11.2020},
  editor  = {OpenVINO},
  url     = {https://github.com/openvinotoolkit/open_model_zoo/tree/master/demos/python_demos/action_recognition},
  urldate = {29.11.2020},
}

@Misc{OpenVINO.HeadAdas,
  title   = {head-pose-estimation-adas-0001},
  year    = {03.10.2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/latest/omz_models_intel_head_pose_estimation_adas_0001_description_head_pose_estimation_adas_0001.html},
  urldate = {03.10.2019},
}

@Misc{OpenVINO.FDAdas,
  title   = {face-detection-adas-0001},
  year    = {03.10.2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/latest/omz_models_intel_face_detection_adas_0001_description_face_detection_adas_0001.html},
  urldate = {03.10.2019},
}

@Misc{OpenVINO.EmotionRetail,
  title   = {emotion-recognition-retail-0003},
  year    = {03.10.2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/2018_R5/_docs_Retail_object_attributes_emotions_recognition_0003_caffe_desc_emotions_recognition_retail_0003.html},
  urldate = {03.10.2019},
}

@Misc{OpenVINO.ConvertPy,
  title   = {Converting TensorFlow* Object Detection API Models},
  year    = {25.03.2019},
  editor  = {OpenVINO},
  url     = {https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html},
  urldate = {25.03.2019},
}


@Article{Ordonez:2016,
  title     = {Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition},
  author    = {Ord{\'o}{\~n}ez, Francisco Javier and Roggen, Daniel},
  journal   = {Sensors},
  volume    = {16},
  number    = {1},
  pages     = {115},
  year      = {2016},
  publisher = {Multidisciplinary Digital Publishing Institute},
  doi       = {10.3390/s16010115},
  note      = {\href{../../MLbib/DeepLearning/sensors-16-00115.pdf}{[pdf]}},
  url       = {https://www.mdpi.com/1424-8220/16/1/115},
  issn      = {1424-8220},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% P
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@Book{Paass:2020,
  author    = {{Paaß, Gerhard and Hecker, Dirk}},
  year      = {2020},
  title     = {{Künstliche Intelligenz, Was steckt hinter der Technologie der Zukunft?}},
  keywords  = {Bildverarbeitung, Bilderkennung, Objektklassifikation},
  address   = {Wiesbaden},
  edition   = {1.},
  publisher = {{Springer Vieweg}},
  note      = {\href{Paaß-Hecker2020_Chapter_WasKannKünstlicheIntelligenz.pdf}{[pdf]}},
  url = {https://link.springer.com/content/pdf/10.1007%2F978-3-658-30211-5_2.pdf}
}

@online{pandas:2021,
  editor = {{pandas}},
  year   = 2021,
  title  = {About-pandas},
  date   = {20.06.2021},
  url    = {https://pandas.pydata.org/about/index.html},
}

@misc{Pansare:2018,
  title         = {Deep Learning with Apache SystemML},
  author        = {Pansare, Niketan and Dusenberry, Michael and Jindal, Nakul and  Boehm, Matthias and Reinwald, Berthold  and  Sen, Prithviraj},
  year          = {2018},
  eprint        = {1802.04647},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  note          = {\href{../../ExterneDokumente/Framework/1802.04647.pdf}{[pdf]}},
}

@article{PiatetskyShapiro:1990,
  abstract = {The growth in the amount of available databases far outstrips the growth of corresponding knowledge. This creates both a need and an opportunity for extracting knowledge from databases. Many recent results have been reported on extracting different kinds of knowledge from databases, including diagnostic rules, drug side effects, classes of stars, rules for expert systems, and rules for semantic query optimization.},
  author   = {Piatetsky-Shapiro, Gregory},
  year     = {1990},
  title    = {Knowledge Discovery in Real Databases: A Report on the IJCAI-89 Workshop},
  url      = {https://ojs.aaai.org/index.php/aimagazine/article/view/873},
  pages    = {68},
  volume   = {11},
  number   = {4},
  journal  = {AI Magazine},
  doi      = {10.1609/aimag.v11i4.873},
}

@article{Pfeifer:2016,
  author  = {Pfeifer, Felix},
  year    = {2016},
  title   = {Raspberry Pi einrichten},
  volume  = {10},
  journal = {Make},
}

@Misc{Polamuri:2017,
  title  = {Difference Between Softmax Function and Sigmoid Function},
  author = {Polamuri, Saimadhu},
  year   = {2017},
  note   = {Eingesehen am 19.12.2019 [online]},
  url    = {https://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/}
}


@article{Pyo:2002,
  abstract = {The knowledge discovery in database (KDD) with data mining is a useful tool for the destination management, and more hospitality enterprises and tourist destinations will adopt it in the future. Destination knowledge management requires a multidisciplinary approach and an understanding of tourism. Research and information technology together are imperative to be successful in KDD and data mining. Since useful knowledge management systems must be timely, the destination knowledge discovery system can be a perpetual prototype requiring frequent updating with emphasis on speed in responses and updating. This article discusses various aspects of KDD including operational issues, applications, and data mining. In addition, a hypothetical example of the KDD is provided using Cheju Island in South Korea.},
  author   = {Pyo, Sungsoo and Uysal, Muzaffer and Chang, Hyesook},
  year     = {2002},
  title    = {Knowledge Discovery in Database for Tourist Destinations},
  pages    = {374--384},
  volume   = {40},
  number   = {4},
  issn     = {0047-2875},
  journal  = {Journal of Travel Research},
  doi      = {10.1177/0047287502040004006},
}

@Online{Python:2020,
  title  = {glob — Unix style pathname pattern expansion},
  editor = {Python Software Foundation},
  year   = {2020},
  note   = {Eingesehen am 15.12.2019 [online]},
  url    = {https://docs.python.org/3/library/glob.html}
}

@Online{Python:2020b,
  title  = {math — Mathematical functions},
  editor = {Python Software Foundation},
  year   = {2020},
  note   = {Eingesehen am 15.12.2019 [online]},
  url    = {https://docs.python.org/3/library/math.html},
  key    = {math}
}

%numpy
@Online{Python:2020c,
  title  = {numpy},
  editor = {Python Software Foundation},
  year   = {2020},
  note   = {Eingesehen am 15.12.2019 [online]},
  url    = {https://numpy.org/},
  key    = {numpy}
}

@Online{Python:2020d,
  title  = {random},
  editor = {Python Software Foundation},
  year   = {2020},
  note   = {Eingesehen am 16.12.2019 [online]},
  url    = {https://docs.python.org/3/library/random.html},
  key    = {random}
}

@Online{Python:2020e,
  title  = {python-pickle-module-save-objects-serialization},
  editor = {Python Software Foundation},
  year   = {2020},
  note   = {Eingesehen am 17.12.2019 [online]},
  url    = {https://pythonprogramming.net/python-pickle-module-save-objects-serialization/},
  key    = {pickel}
}

@online{Python:2020System,
  editor  = {Python Software Foundation},
  year    = {2020},
  title   = {System-specific parameters and functions},
  url     = {https://docs.python.org/3.5/library/sys.html},
  urldate = {2021-06-20},
}

@online{Python:2020Time,
  editor  = {Python Software Foundation},
  year    = {2020},
  title   = {Time access and conversions},
  url     = {https://docs.python.org/3.5/library/time.html},
  urldate = {2021-06-20},
}

@online{PyTorch:2020,
  editor  = {Facebook},
  year    = {2020},
  title   = {PyTorch},
  url     = {https://pytorch.org/},
  urldate = {24/07/2020},
}


@Online{PyPI:2021,
  title  = {The Python Package Index},
  editor = {Python Software Foundation},
  year   = {2021},
  url    = {https://pypi.org},
}


@Online{PyPI:2021b,
  title  = {pycocotools},
  editor = {Python Software Foundation},
  year   = {2021},
  url    = {https://pypi.org/project/pycocotools},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Q
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{qi:2018,
	title     = {Low-shot learning with imprinted weights},
	author    = {Qi, Hang and Brown, Matthew and Lowe, David G},
	booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages     = {5822--5830},
	year      = {2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@online{Rahner:2021,
  author  = {Rahner, Reinhard},
  year    = {2021},  
  title   = {{Der I2C Bus}},
  url     = {https://www.rahner-edu.de/grundlagen/signale-richtig-verstehen/i2c-besser-verstehen-1/},
  urldate = {2021-06-09},
} 
		

@online{RaspberryPi3:2019,
  editor  = {{Raspberry Pi Foundation}},
  year    = {2019},
  title   = {Raspberry Pi 3 Model B+},
  url     = {https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus},
  urldate = {14/11/2019},
}

@online{RaspberryPiCam:2016,
  editor  = {{Raspberry Pi Foundation}},
  year    = {2016},
  title   = {Raspberry Pi Camera Module V2},
  url     = {https://www.raspberrypi.org/products/camera-module-v2/},
  urldate = {14/11/2019},
}

@online{RaspberryOS:2019,
  editor  = {{Raspberry Pi Foundation}},
  year    = {2019},
  title   = {Raspberry Pi OS},
  url     = {https://www.raspberrypi.org/downloads/raspberry-pi-os/},
  urldate = {14/11/2019},
}

@online{KI:2020,
	author  = {Raveling, Jann},
	year    = 2020,
	title   = {Was ist künstliche Intelligenz? },
	url     = {https://www.wfb-bremen.de/de/page/stories/digitalisierung-industrie40/was-ist-kuenstliche-intelligenz-definition-ki},
	urldate = {09/06/2020},
}

@article{Rosebrock:2017,
  title     = {Raspbian Stretch: Install OpenCV 3 + Python on your Raspberry Pi},
  author    = {Rosebrock, Adrian},
  year      = 2017,
  url       = { https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/},
  publisher = {PyImageSearch},
}

@online{Redmon.04.12.2020,
  abstract = {MNIST is a great dataset in awful packaging. Here's a CSV instead of that crazy format they are normally available in. Enjoy!},
  author   = {Redmon, Joseph},
  year     = {2020},
  title    = {MNIST in CSV},
  url      = {https://pjreddie.com/projects/mnist-in-csv/},
  urldate  = {04.12.2020}
}


@online{Redmon.08.06.2015,
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.  Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  author   = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  date     = {08.06.2015},
  year     = 2015,
  title    = {You Only Look Once: Unified, Real-Time Object Detection},
  url      = {https://arxiv.org/pdf/1506.02640.pdf},
  urldate  = {17.02.2021},
}


@online{Redmon.17.02.2021,
  abstract = {You only look once (YOLO) is a state-of-the-art, real-time object detection system.},
  author   = {Redmon, Joseph},
  year     = {2021},
  title    = {YOLO: Real-Time Object Detection},
  url      = {https://pjreddie.com/darknet/yolo/},
  urldate  = {17.02.2021}
}

@Book{Rich:1983,
  title     = {Artificial Intelligence},
  author    = {Rich, Elaine},
  publisher = {McGraw-Hill Inc.,US},
  year      = 1983,
  isbn      = {9780070522619},
}

@MastersThesis{Rubin:2020,
  author   = {Rubin, Marco},
  school   = {Technische Universität München},
  title    = {Evaluation of Machine Learning Inference Workloads on Heterogeneous Edge Devices},
  year     = {2020},
  type     = {Bachelorarbeit},
  keywords = {machine learning, edge device},
}

@book{Runkler.2015,
  title     = {Data Mining – Modelle und Algorithmen intelligenter Datenanalyse},
  author    = {Runkler, Thomas A.},
  volume    = {2},
  year      = {2015},
  publisher = {Springer Fachmedien}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% S
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{Sachs.2006,
  title     = {Angewandte Statistik – Methodensammlung mit R},
  author    = {Sachs, Lothar and Hedderich, Jürgen},
  volume    = {12},
  year      = {2006},
  publisher = {Springer-Verlag}
}


@article{Sahni:2006,
  author  = {Sahni,Vishal and Patvardhan,C.},
  title   = {Iris Data Classification Using Quantum Neural Networks},
  journal = {AIP Conference Proceedings},
  volume  = {864},
  number  = {1},
  pages   = {219--227},
  year    = {2006},
  doi     = {10.1063/1.2400893},
  url     = {https://aip.scitation.org/doi/abs/10.1063/1.2400893},
  eprint  = {https://aip.scitation.org/doi/pdf/10.1063/1.2400893},
}


@manual{SamsungExynos980:2020,
  editor = {Samsung},
  title  = {Samsung Exynos-980},
  year   = 2020,
  note   = {\url{https://www.samsung.com/semiconductor/minisite/exynos/products/mobileprocessor/exynos-980/}{Samsung Exynos-980}},
}

@article{MobileNet:2018,
  author        = {{Sandler}, Mark and {Howard}, Andrew and {Zhu}, Menglong and
                   {Zhmoginov}, Andrey and {Chen}, Liang-Chieh},
  title         = "{MobileNetV2: Inverted Residuals and Linear Bottlenecks}",
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  year          = "2018",
  month         = "Jan",
  eid           = {arXiv:1801.04381},
  archivePrefix = {arXiv},
  eprint        = {1801.04381},
  primaryClass  = {cs.CV},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2018arXiv180104381S},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  note      = {\textcolor{blue}{\href{../../MLbib/CNN/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf}{[pdf]}}},
}

@Misc{Saha:2018,
  title  = {A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way},
  author = {Saha, Sumit},
  year   = {2018},
  note   = {Eingesehen am 20.01.2020 [online]},
  url    = {https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53},
  urldate = {30.10.2020},
}

@online{SAS:2021,
  author  = {SAS Institue Inc.},
  title   = {Artificial Intelligence - What it is and why it matters},
  url     = {https://www.sas.com/en_us/insights/analytics/what-is-artificial-intelligence.html},
  urldate = {2021-04-13},
}

@online{Saxena:2016,
  author = {Saxena, Abhineet},
  year   = 2016,
  title  = {Convolutional Neural Networks (CNNs): An Illustrated Explanation},
  url    = {https://blog.xrds.acm.org/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/},
}


@online{Schilling:2017,
  author  = {Schilling, Andreas},
  year    = {2017},
  title   = {Intel präsentiert ersten Neural Network Processor},
  url     = {https://www.hardwareluxx.de/index.php/news/hardware/prozessoren/44661-intel-praesentiert-ersten-neural-network-processor.html},
  urldate = {2021-04-13},
}

@InProceedings{Schroff:2015,
  author    = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  title     = {FaceNet: A Unified Embedding for Face Recognition and Clustering},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2015},
  pages     = {815--823},
  note      = {\textcolor{blue}{\href{../../MLbib/CNN/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf}{[pdf]}}},
}

@Inproceedings{Schutten:2016,
  title     = {An Analysis on Better Testing than Training Performances on the Iris Dataset},
  abstract  = {The Iris dataset is a well known dataset containing information on three different types of Iris flowers. A typical and popular method for solving classification problems on datasets such as the Iris set is the support vector machine (SVM). In order to do so the dataset is separated in a set used for training and a set used for testing. The error rate, after training, for the training set should be lower than the error rate on the test set. However, in this paper we show that when solving the classification problem for the Iris dataset with SVMs this is not the case. Therefore, we provide an analysis of the Iris dataset and the classification models in order to find the origin of this interesting observation.},
  keywords  = {Supervised learning, Machine learning, Support Vector Machine},
  author    = {Schutten, Marten and  Wiering, Marco},
  year      = 2016,
  month     = 9,
  day       = 10,
  booktitle = "Belgian Dutch Artificial Intelligence Conference",
  note      = {\href{https://archive.ics.uci.edu/ml/datasets/iris}{Link}, \href{https://www.kaggle.com/uciml/iris}{Link}},
}

@online{Seeed:2021,
  editor  = {seeed},
  year    = {2021},  
  title   = {Sipeed MaixCube – All-in-One AI Development Platform Based on K210 (RISC-V)},
  url     = { https://www.seeedstudio.com/Sipeed-Maix-Cube-p-4553.html},
  urldate = {2021-06-16},
}

@Misc{sentdex:2018,
  title  = {Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2},
  editor = {sentdex},
  year   = {2018},
  note   = {Eingesehen am 20.12.2019 [online]},
  url    = {https://pythonprogramming.net/loading-custom-data-deep-learning-python-tensorflow-keras/}
}

@InProceedings{Shams:2007,
  author    = {Shams, Ramtin  and Barnes, Nick},
  booktitle = {9th Biennial Conference of the Australian Pattern Recognition Society on Digital Image Computing Techniques and Applications ({DICTA} 2007)},
  title     = {Speeding up Mutual Information Computation Using {NVIDIA} {CUDA} Hardware},
  year      = {2007},
  month     = {dec},
  publisher = {{IEEE}},
  doi       = {10.1109/dicta.2007.4426846},
}

@Article{Shang:2016,
  author  = {Shang, Wenling and Sohn, Kihyuk and Almeida, Diogo and Lee, Honglak},
  year    = {2016},
  month   = {03},
  pages   = {2217--2225},
  journal = {International Conference on Machine Learning (ICML)},
  title   = {Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units},
  note    = {\href{../../MLbib/CNN/1603.05201.pdf}{[pdf]}},
}

@InProceedings{Shankar:2020,
  title     = {Evaluating Machine Accuracy on {I}mage{N}et},
  author    = {Shankar, Vaishaal and Roelofs, Rebecca and Mania, Horia and Fang, Alex and Recht, Benjamin and Schmidt, Ludwig},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages     = {8634--8644},
  year      = {2020},
  editor    = {Hal Daumé III and Aarti Singh},
  volume    = {119},
  series    = {Proceedings of Machine Learning Research},
  month     = {13--18 Jul},
  publisher = {PMLR - Proceedings of Machine Learning Research},
  pdf       = {http://proceedings.mlr.press/v119/shankar20c/shankar20c.pdf},
  url       = {http://proceedings.mlr.press/v119/shankar20c.html},
  abstract  = {We evaluate a wide range of ImageNet models with five trained human labelers. In our year-long experiment, trained humans first annotated 40,000 images from the ImageNet and ImageNetV2 test sets with multi-class labels to enable a semantically coherent evaluation. Then we measured the classification accuracy of the five trained humans on the full task with 1,000 classes. Only the latest models from 2020 are on par with our best human labeler, and human accuracy on the 590 object classes is still 4% and 10% higher than the best model on ImageNet and ImageNetV2, respectively. Moreover, humans achieve the same accuracy on ImageNet and ImageNetV2, while all models see a consistent accuracy drop. Overall, our results show that there is still substantial room for improvement on ImageNet and direct accuracy comparisons between humans and machines may overstate machine performance.},
  note      = {\href{../../MLbib/Dataset/shankar20c.pdf}{[pdf]}},
}

@inproceedings{Sharif:2014,
	title     = {CNN features off-the-shelf: an astounding baseline for recognition},
	author    = {Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
	booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
	pages     = {806--813},
	year      = {2014}
}

@book{Sharafi:2013,
 author    = {Sharafi, Armin},
 year      = {2013},
 title     = {Knowledge Discovery in Databases},
 address   = {Wiesbaden},
 publisher = {{Springer Fachmedien Wiesbaden}},
 isbn      = {978-3-658-02001-9},
 doi       = {10.1007/978-3-658-02002-6},
}

@online{AIUnitedRedaktion.20.12.2018,
 abstract = {Sigmoid, tanh, Softmax, ReLU, Leaky ReLU erkl{\"a}rt!!! Was ist eine Aktivierungsfunktion? Es ist nur ein Element (Knoten), dass Sie zur Ausgabe eines neuronalen Netzwerks hinzuf{\"u}gen. Es wird auch als {\"U}bertragungsfunktion bezeichnet. Es kann auch zwischen zwei neuronalen Netzwerken angeschlossen werden. Warum verwendet man Aktivierungsfunktionen in neuronalen Netzwerken? Es wird verwendet, um die Ausgabe des neuronalen [$\ldots$]},
 editor   = {AI-United},
 author   = {Sharma, Sagar},
 year     = {20.12.2018},
 title    = {Aktivierungsfunktionen: Neuronale Netze},
 url      = {http://www.ai-united.de/aktivierungsfunktionen-neuronale-netze/},
 urldate  = {11.11.2020},
}

@online{Sharma:2017,
  author = {Sharma, Vaibhav},
  year   = 2017,
  title  = {Predicting bitcoin's Value Using Convolution neural networks \& Long short term memory cells !},
  url    = {https://machinelearners.net/2017/08/23/predicting-bitcoins-value-using-convolution-neural-networks-long-short-term-memory-cells/},
}

@article{Sharma:2018,
 author   = {Sharma, Neha and Jain, Vibhor and Mishra, Anju},
 year     = {2018},
 title    = {An Analysis Of Convolutional Neural Networks For Image Classification},
 keywords = {CNN;Deep Learning;Neural network;Object classification;Object detection},
 pages    = {377--384},
 volume   = {132},
 issn     = {18770509},
 journal  = {Procedia Computer Science},
 doi      = {10.1016/j.procs.2018.05.198},
 file     = {1-s2.0-S1877050918309335-main:C\:\\Users\\chris\\Desktop\\EP\\Master\\3. Semester\\Projekt\\200915JetsonNano\\Citavi\\KI mit Jetson Nano\\Citavi Attachments\\1-s2.0-S1877050918309335-main.pdf:pdf}
}

@article{Shin:2016,
	title     = {Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning},
	author    = {Shin, Hoo-Chang and Roth, Holger R and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M},
	journal   = {IEEE transactions on medical imaging},
	volume    = {35},
	number    = {5},
	pages     = {1285--1298},
	year      = {2016},
	publisher = {IEEE},
	doi       = {10.1109/TMI.2016.2528162}}
}


@ARTICLE{Shu:2021,
  author  = {Shu, Xiangbo and Zhang, Liyan and Sun, Yunlian and Tang, Jinhui},
  journal = {IEEE Transactions on Neural Networks and Learning Systems}, 
  title   = {Host–Parasite: Graph LSTM-in-LSTM for Group Activity Recognition}, 
  year    = {2021},
  volume  = {32},
  number  = {2},
  pages   = {663-674},
  doi     = {10.1109/TNNLS.2020.2978942}
}

@inproceedings{Siddique:2019,
  author    = {Siddique, F. and Sakib, S. and Siddique, M. A. B.},
  booktitle = {2019 5th International Conference on Advances in Electrical Engineering (ICAEE)}, 
  title     = {Recognition of Handwritten Digit using Convolutional Neural Network in Python with Tensorflow and Comparison of Performance for Various Hidden Layers}, 
  year      = {2019},
  pages     = {541--546},
  note      = {\href{../../MLbib/Dataset/1909.08490.pdf}{[pdf]}},
}

@online{Sipeed:2021,
  editor  = {Sipeed Ltd},
  year    = {2018-2021},
  title   = {image (machine vision)},
  url     = {https://cn.maixpy.sipeed.com/maixpy/en/api_reference/machine_vision/image/image.html},
  urldate = {2021-06-20},
} 

@online{Sipeed:2021LCD,
  editor  = {Sipeed Ltd},
  year    = {2018-2021},
  title   = {lcd (screen display)},
  url     = {https://cn.maixpy.sipeed.com/maixpy/en/api_reference/machine_vision/lcd.html},
  urldate = {2021-06-20},
}

@online{Sipeed:2021Sensor,
  editor  = {Sipeed Ltd},
  year    = {2018-2021},
  title   = {sensor (camera)},
  url     = {https://cn.maixpy.sipeed.com/maixpy/en/api_reference/machine_vision/sensor.html},
  urldate = {2021-06-20},
}

@online{Sipeed:2021KPU,
  editor  = {Sipeed Ltd},
  year    = {2018-2021},
  title   = {KPU},
  url     = {https://cn.maixpy.sipeed.com/maixpy/en/api_reference/Maix/kpu.html},
  urldate = {2021-06-20},
}

@online{Sipeed:2021FPIOA,
  editor  = {Sipeed Ltd},
  year    = {2018-2021},
  title   = {fpioa manager},
  url     = {https://cn.maixpy.sipeed.com/maixpy/en/api_reference/builtin_py/fm.html},
  urldate = {2021-06-20},
}

@online{Sipeed:2021MaixPy,
  editor  = {Sipeed Ltd},
  year    = {2020},  
  title   = {MaixPy Documentation},
  url     = {https://maixpy.sipeed.com/dev/en/},
  urldate = {2021-04-16},
}


@misc{Simonyan:2015,
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
  author        = {Simonyan, Karen  and  Zisserman, Andrew},
  year          = {2015},
  eprint        = {1409.1556},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  note          = {\textcolor{blue}{\href{../../MLbib/CNN/1409.1556.pdf}{[pdf]}}},
}

@misc{Sitawarin:2018,
  title         = {DARTS: Deceiving Autonomous Cars with Toxic Signs}, 
  author        = {Sitawarin, Chawin and Bhagoji, Arjun Nitin and Mosenia, Arsalan and Chiang, Mung and Mittal, Prateek},
  year          = {2018},
  eprint        = {1802.06430},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR},
  note          = {\textcolor{blue}{\href{../../MLbib/Adversarial/1802.06430.pdf}{[pdf]}}},
}

@article{scikit-learn:2011,
  title={Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.  and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@article{Stahl:2019,
	author  = {Stahl, Achim},
	year    = {2019},
	title   = {{Künstliche Intelligenz, komprimiert auf einem USB-Stick}},
	page    = {33},
	volume  = {4},
	issn    = {0341-5589},
	journal = {{Elektronik Praxis}},
	note    = "\textcolor{blue}{\href{QuellenAlsPDF/QuellenEinleitung/ElektronikPraxis.pdf}{[pdf]}}"
}

@online{STMicroelectronics:2020,
	editor = {{STMicroelectronics International NV}},
	year   = 2020,
	title  = {HTS221 - Capacitive digital sensor for relative humidity and temperature},
	date   = {03.05.2021},
	url    = {https://www.st.com/resource/en/datasheet/hts221.pdf},
}

@online{STMicroelectronics:2017,
  author    = {{ST Microelectronics International NV}},
  year      = 2017,
  ALTauthor = {ST Microelectronics International NV},
  ALTeditor = {ST Microelectronics International NV},
  title     = {LSM9DS1},
  date      = {03.05.2021},
  url       = {https://www.stmicroelectronics.com.cn/resource/en/datasheet/lsm9ds1.pdf},
}	
	
@online{Stock.07.01.2021,
  abstract      = {In this paper we outline the development methodology for an automatic dog treat dispenser which combines machine learning and embedded hardware to identify and reward dog behaviors in real-time. Using machine learning techniques for training an image classification model we identify three behaviors of our canine companions: {\textquotedbl}sit{\textquotedbl}, {\textquotedbl}stand{\textquotedbl}, and {\textquotedbl}lie down{\textquotedbl} with up to 92{\%} test accuracy and 39 frames per second. We evaluate a variety of neural network architectures, interpretability methods, model quantization and optimization techniques to develop a model specifically for an NVIDIA Jetson Nano. We detect the aforementioned behaviors in real-time and reinforce positive actions by making inference on the Jetson Nano and transmitting a signal to a servo motor to release rewards from a treat delivery apparatus.},
  author        = {Stock, Jason and Cavey, Tom},
  date          = {07.01.2021},
  year          = {2021},
  title         = {Who's a Good Boy? Reinforcing Canine Behavior in Real-Time using Machine  Learning},
  url           = {https://arxiv.org/pdf/2101.02380.pdf},
  urldate       = {27.02.2021},
  eprint        = {2101.02380},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV}
}

@book{StackOverflow:2019,
  title  = {Learning TensorFlow},
  year   = 2019,
  editor = {{Stack Overflow Documentation}},
  url    = {riptutorial.com/tensorflow},
  note   = {\href{../../MLbib/TensorFlow/tensorflow.pdf}{[pdf]}},
}  


@online{Starlino:2009,
  editor = {{Starlino Electronics}},
  year   = 2009,
  title  = {A Guide To using IMU (Accelerometer and Gyroscope Devices) in Embedded Applications},
  date   = {26.06.2021},
  url    = {http://www.starlino.com/imu_guide.html},
}

@online{Starlino:2011,
  editor = {{Starlino Electronics}},
  year   = 2011,
  title  = {DCM Tutorial – An Introduction to Orientation Kinematics},
  date   = {26.06.2021},
  url    = {http://www.starlino.com/dcm_tutorial.html},
}


 
@misc{Szegedy:2014,
  title         = {Going Deeper with Convolutions}, 
  author        = {Szegedy, Christian and  Liu, Wei and  Jia, Yangqing and  Sermanet, Pierre and Reed, Scott  and  Anguelov, Dragomir and Erhan, Dumitru and  Vanhoucke, Vincent and Rabinovich, Andrew },
  year          = {2014},
  eprint        = {1409.4842},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  note          = {\textcolor{blue}{\href{../../MLbib/CNN/1409.4842v1.pdf}{[pdf]}}},
   
} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% T
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{Tan:2020,
  title         = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
  author        = {Tan, Mingxing  and Le, Quoc V.},
  year          = {2020},
  eprint        = {1905.11946},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  note          = {\textcolor{blue}{\href{../../MLbib/CNN/1905.11946.pdf}{[pdf]}}},
}
 
@inbook{Tan:2019,
  author  = {Tan, Sing and Sidhu, Amandeep},
  year    = {2019},
  month   = {04},
  pages   = {63-67},
  title   = {CUDA implementation},
  isbn    = {978-3-030-17273-2},
  journal = {Studies in Computational Intelligence},
  doi     = {10.1007/978-3-030-15585-8_5}
}

@article{Taylor:2009,
	title   = {Transfer learning for reinforcement learning domains: A survey.},
	author  = {Taylor, Matthew E and Stone, Peter},
	journal = {Journal of Machine Learning Research},
	volume  = {10},
	number  = {7},
	year    = {2009}
}

@article{Theano:2016,
   author = {
     Rami Al-Rfou and
     Guillaume Alain and
     Amjad Almahairi and
     Christof Angermueller and
     Dzmitry Bahdanau and
     Nicolas Ballas and
     Fr\'ed\'eric Bastien and
     Justin Bayer and
     Anatoly Belikov and
     Alexander Belopolsky and
     Yoshua Bengio and
     Arnaud Bergeron and
     James Bergstra and
     Valentin Bisson and
     Josh {Bleecher Snyder} and
     Nicolas Bouchard and
     Nicolas Boulanger-Lewandowski and
     Xavier Bouthillier and
     Alexandre de Br\'ebisson and
     Olivier Breuleux and
     Pierre-Luc Carrier and
     Kyunghyun Cho and
     Jan Chorowski and
     Paul Christiano and
     Tim Cooijmans and
     Marc-Alexandre C\^ot\'e and
     Myriam C\^ot\'e and
     Aaron Courville and
     Yann N. Dauphin and
     Olivier Delalleau and
     Julien Demouth and
     Guillaume Desjardins and
     Sander Dieleman and
     Laurent Dinh and
     M\'elanie Ducoffe and
     Vincent Dumoulin and
     Samira {Ebrahimi Kahou} and
     Dumitru Erhan and
     Ziye Fan and
     Orhan Firat and
     Mathieu Germain and
     Xavier Glorot and
     Ian Goodfellow and
     Matt Graham and
     Caglar Gulcehre and
     Philippe Hamel and
     Iban Harlouchet and
     Jean-Philippe Heng and
     Bal\'azs Hidasi and
     Sina Honari and
     Arjun Jain and
     S\'ebastien Jean and
     Kai Jia and
     Mikhail Korobov and
     Vivek Kulkarni and
     Alex Lamb and
     Pascal Lamblin and
     Eric Larsen and
     C\'esar Laurent and
     Sean Lee and
     Simon Lefrancois and
     Simon Lemieux and
     Nicholas L\'eonard and
     Zhouhan Lin and
     Jesse A. Livezey and
     Cory Lorenz and
     Jeremiah Lowin and
     Qianli Ma and
     Pierre-Antoine Manzagol and
     Olivier Mastropietro and
     Robert T. McGibbon and
     Roland Memisevic and
     Bart van Merri\"enboer and
     Vincent Michalski and
     Mehdi Mirza and
     Alberto Orlandi and
     Christopher Pal and
     Razvan Pascanu and
     Mohammad Pezeshki and
     Colin Raffel and
     Daniel Renshaw and
     Matthew Rocklin and
     Adriana Romero and
     Markus Roth and
     Peter Sadowski and
     John Salvatier and
     Fran\c{c}ois Savard and
     Jan Schl\"uter and
     John Schulman and
     Gabriel Schwartz and
     Iulian Vlad Serban and
     Dmitriy Serdyuk and
     Samira Shabanian and
     \'Etienne Simon and
     Sigurd Spieckermann and
     S. Ramana Subramanyam and
     Jakub Sygnowski and
     J\'er\'emie Tanguay and
     Gijs van Tulder and
     Joseph Turian and
     Sebastian Urban and
     Pascal Vincent and
     Francesco Visin and
     Harm de Vries and
     David Warde-Farley and
     Dustin J. Webb and
     Matthew Willson and
     Kelvin Xu and
     Lijun Xue and
     Li Yao and
     Saizheng Zhang and
     Ying Zhang},
   collaboration = {Theano Development Team},
  title          = "{Theano: A {Python} framework for fast computation of mathematical expressions}",
  journal        = {arXiv e-prints},
  volume         = {abs/1605.02688},
  primaryClass   = "cs.SC",
  keywords       = {Computer Science - Symbolic Computation, Computer Science - Learning, Computer Science - Mathematical Software},
  year           = 2016,
  month          = may,
  url            = {http://arxiv.org/abs/1605.02688},
  note           = {\href{../../ExterneDokumente/Framework/1605.02688.pdf}{[pdf]},  \href{http://www.deeplearning.net/software/theano/}{[Link]}},
}

@incollection{Torrey:2010,
	title     = {Transfer learning},
	author    = {Torrey, Lisa and Shavlik, Jude},
	booktitle = {Handbook of research on machine learning applications and trends: algorithms, methods, and techniques},
	pages     = {242--264},
	year      = {2010},
	publisher = {IGI global}
}

@online{TU.2009,
  title  = {Data-Mining und KDD – ein Überblick},
  editor = {TU Dresden},
  year   = {2009},
  url    = {https://docplayer.org/3847349-Data-mining-und-knowledge-discovery-in-databases-kdd-ein-ueberblick.html}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% U
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Umana:2019,
  abstract = {The purpose of this blog is to guide users on the creation of a custom object detection model with performance optimization to be used on an NVidia Jetson Nano. This is a report for a final project$\ldots$},
  author   = {Uma{\~n}a, Edward},
  year     = {2019},
  title    = {Nvidia Jetson Nano: Custom Object Detection from scratch using Tensorflow and OpenCV},
  url      = {https://medium.com/swlh/nvidia-jetson-nano-custom-object-detection-from-scratch-using-tensorflow-and-opencv-113fe4dba134},
  keywords = {Jetson Nano, TensorFlow, Jupyter, OpenCV, Training, Object Detection},
  urldate  = {29.10.2020},
  journal  = {The Startup},
}  

@online{Goettingen,
  title  = {Kapitel 3: Erste Schritte der Datenanalyse},
  editor = {Univeristät Göttingen},
  url    = {https://www.uni-goettingen.de/de/document/download/9b4b2033cba125be183719130e524467.pdf/mvsec3.pdf}
}


@online{UCIIris:2021,
  author    = {Fisher, R. A.},
  title     = {Fisher's Iris Dataset},
  publisher = {Center for Machine Learning and Intelligent Systems},
  institute = {University of California, Irvine},
  url       = {https://archive.ics.uci.edu/ml/datasets/iris},
  date      = {15.05.2021},
  year      = 1936,
  note      = {\href{../../ExterneDokumente/Dataset/.pdf}{[pdf]}},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% V
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{VanGinneken:2015,
	title        = {Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans},
	author       = {Van Ginneken, Bram and Setio, Arnaud AA and Jacobs, Colin and Ciompi, Francesco},
	booktitle    = {2015 IEEE 12th International symposium on biomedical imaging (ISBI)},
	pages        = {286--289},
	year         = {2015},
	organization = {IEEE}
}

@online{Vilsbeck:2019,
  author  = {Vilsbeck, Christian},
  year    = {2019},  
  title   = {KI in der Automatisierung},
  url     = {https://www.industr.com/de/ki-in-der-automatisierung-2361205},
  urldate = {2021-06-16},
}

@article{Vincent:2018,
  title   = {Google unveils tiny new AI chips for on-device machine learning},
  author  = {Vincent, James},
  year    = 2018,
  journal = {The Verge},
  url     = {https://www.theverge.com/2018/7/26/17616140/google-edge-tpu-on-device-ai-machine-learning-devkit},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% W
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@Misc{Wageningen:2019,
  author  = {{Wageningen University \& Research} and DellEMC},
  \url    = {https://wiki.anunna.wur.nl/images/e/eb/WUR_CUDA_210619.pdf},
  title   = {GPU Computing with NVIDIA CUDA},
  year    = {2019},
  urldate = {21/06/2019},
}

@Article{Wang:2016,  
  author  = {Wang, F. and  Zhang, J. J. and Zheng, X.  and Wang, X.  and Yuan, Y. and Dai, X. and Zhang, J.  and Yang, L. },
  journal = {IEEE/CAA Journal of Automatica Sinica},   
  title   = {Where does AlphaGo go: from church-turing thesis to AlphaGo thesis and beyond},   
  year    = {2016},  
  volume  = {3},  
  number  = {2}, 
  pages   = {113-120}, 
  doi     = {10.1109/JAS.2016.7471613},
}


@InCollection{Wang:2014,
  author    = {Wang, Endong  and Zhang, Qing  and Shen, Bo  and Zhang, Guangyong  and Lu, Xiaowei  and Wu, Qing  and Wang, Yajuan },
  booktitle = {High-Performance Computing on the Intel{\textregistered} Xeon Phi{\texttrademark}},
  publisher = {Springer International Publishing},
  title     = {Intel Math Kernel Library},
  year      = {2014},
  pages     = {167--188},
  doi       = {10.1007/978-3-319-06486-4_7},
}

@article{Wartala:2020,
  author    = {Wartala , Ramon},
  title     = {Willkommen bei den Jetsons},
  year      = 2020,
  publisher = {Heise Medien GmbH \& Co. KG},
  journal   = {iX Magazin},
  volume    = 8,
  pages     = {134--139},
  note      = "\href{../../ExterneDokumente/JetsonNano/iX8_2020Jetsons.pdf}{pdf} \href{https://www.heise.de/select/ix/2020/8/softlinks/z92c?wt_mc=pred.red.ix.ix082020.134.softlink.softlink}{[source]}",
}

@article{Wartala:2020b,
  author    = {Wartala , Ramon},
  title     = {Deep-Learning-Anwendungen mit Nvidias Jetson Nano},
  year      = 2020,
  publisher = {Heise Medien GmbH \& Co. KG},
  journal   = {iX Magazin},
  volume    = 2,
  pages     = {54--59},
  note      = "\href{../../ExterneDokumente/JetsonNano/iX2_2020Jetson.pdf}{pdf} \href{https://www.heise.de/select/ix/2020/8/softlinks/z92c?wt_mc=pred.red.ix.ix082020.134.softlink.softlink}{[source]}",
}

@book{Warden:2020,
 author   = {Warden, Pete and Situnayake, Daniel},
 title    = {TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
 keywords = {TensorFlow Lite, Google Colab, Keras, Jupyter Notebook},
 isbn     = {978-1-492-05204-3},
 year     = 2020
}

@report{Weber:1997,
  author    = {Weber, Allan},
  title     = {The USC-SIPI Image Database: Version 5},
  year      = 1997,
  institute = {Processing Institute}, 
  publisher = {University of Southern California},
  volume    = 315,
  url       = {http://sipi.usc.edu/services/ database/Database.html},
  note      = {\href{https://datafireball.com/2016/09/24/lena-the-origin-about-the-de-facto-test-image/}{link}},
}

@Inbook{Weik:2001,
  author    = {Weik, Martin H.},
  title     = {direct memory access},
  bookTitle = {Computer Science and Communications Dictionary},
  year      = {2001},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {422--422},
  isbn      = {978-1-4020-0613-5},
  doi       = {10.1007/1-4020-0613-6_5165},
  url       = {https://doi.org/10.1007/1-4020-0613-6_5165}
}
  
@Misc{Werle:2020,
  year   = {2020},
  author = {Werle, Thomas},
  title  = {Künstliche Intelligenz Revolution oder Hype},
  note   = {Eingesehen am 10.12.2019 [online]},
  url    = {https://www.bundesregierung.de/breg-de/aktuelles/fragen-und-antworten-ki-1704494}
}

@online{West:2019,
  author = {West, Mark},
  title  = {Adding AI to the Raspberry Pi with the Movidius Neural Compute Stick},
  year   = 2019,
  url    ={https://www.bouvet.no/bouvet-deler/adding-ai-to-edge-devices-with-the-movidius-neural-compute-stick},
}
 

@Misc{WesternDigital:2018,
  editor  = {{Western Digital}},
  note    = {\url{https://www.westerndigital.com/products/internal-drives/pc-sn720-ssd}},
  title   = {PC SN720 NVMe\textsuperscript{\texttrademark} SSD},
  year    = {2018},
  urldate = {06/09/2018},
}
 
@online{Win32DiskImage:2020,
  title  = {Win32 Disk Imager},
  author = {Davis, Tobin and Davis, Justin},
  year   = 2020,
  url    = {https://sourceforge.net/projects/win32diskimager/},
}

@article{Wrobel:1998,
 author  = {Wrobel, Stefan},
 year    = {1998},
 title   = {Data Mining und Wissensentdeckung in Datenbanken},
 url     = {ftp://ftp.fhg.de/archive/gmd/ais/publications/1998/wrobel.98.data-mining.pdf},
 urldate = {14.11.2020},
 number  = {1},
 journal = {K{\"u}nstliche Intelligenz},
}

@online{Wuttke:2020,
  title  = {Einführung in neuronale Netzwerke},
  author = {Wuttke, Laurenz},
  year   = {2020},
  note   = {Eingesehen am 18.12.2019 [online]},
  url    = {https://datasolut.com/neuronale-netzwerke-einfuehrung/},
  key    = {Neuronale Netze}
}

@online{Wuttke:2021,
  author  = {Wuttke, Laurenz},
  year    = {2021},
  title   = {Machine Learning: Definition, Algorithmen, Methoden und Beispiele},
  url     = {https://datasolut.com/was-ist-machine-learning/},
  urldate = {2021-04-13},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% X
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{Xilinx:2021,
  title     = {Product Brief - Kria KV260 Vision AI Starter Kit },
  editor    = {XILINX},
  year      = {2021},
  publisher = {XILINX},
  url       = {https://www.mouser.de/pdfDocs/xilinx-kv260-product-brief.pdf},
  urldate   = {16.06.2021},
}
  
@online{Xilinx:2021b,
  editor  = {XILINX},
  year    = {2021},  
  title   = {Kria KV260 Vision AI Starter Kit},
  url     = {https://www.xilinx.com/products/som/kria/kv260-vision-starter-kit.html},
  urldate = {2021-06-16},
}
  
@online{Xilinx:2021c,
  editor  = {XILINX},
  year    = {2021},  
  title   = {Defect Detection Accelerated Application},
  url     = {https://www.xilinx.com/products/app-store/kria/defect-detection.html},
  urldate = {2021-06-16},
}

@online{XILINX:2021d,
  editor  = {XILINX},
  year    = {2021},  
  title   = {Smart Camera Accelerated Application},
  url     = { https://www.xilinx.com/products/app-store/kria/smart-camera.html},
  urldate = {2021-06-16},
}

@misc{XILINX:2021e,
  author  = {XILINX},
  title   = {Kria K26 SOM: The Ideal Platform for Vision AI at the Edge},
  year    = {2021},
  url     = {https://www.mouser.de/pdfDocs/wp529-som-benchmarks.pdf},
  urldate = {2021-06-16},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Y
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Z
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{Zakaria:2016,
  author  = {Zakaria, Rada},
  year    = {2016},
  title   = {Smart Motion Detection: Security System Using Raspberry Pi},
  volume  = {30},
  journal = {Journal of the Engineering Research Institute},
}

@misc{Zhang:2015,
  title         = {Accelerating Very Deep Convolutional Networks for Classification and Detection}, 
  author        = {Zhang, Xiangyu and  Zou, Jianhua and  He, Kaiming and  Sun, Jian},
  year          = {2015},
  eprint        = {1505.06798},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  note          = {\textcolor{blue}{\href{../../MLbib/CNN/1505.06798.pdf}{[pdf]}}},
}

@misc{Zhang:2019b,
  title  = {Padding and Stride},
  author = {Zhang},
  year   = {2019},
  note   = {Eingesehen am 19.12.2019 [online]},
  url    = {https://d2l.ai/chapter_convolutional-neural-networks/index.html}
}


%voheriger Schlüssel ".29.10.2020"
@Online{Zhang:2019,
  author   = {Zhang, Chengwei},
  editor   = {DLology},
  year     = {2019},
  title    = {How to run TensorFlow Object Detection model on Jetson Nano - DLology},
  url      = {https://www.dlology.com/blog/how-to-run-tensorflow-object-detection-model-on-jetson-nano/},
  keywords = {TensorFlow, Tutorial, Jetson Nano, TensorRT},
  urldate  = {29.10.2020},
}

@Inproceedings{Zhiqiang:2017,
	author    = {Zhiqiang, W. and Jun, L.},
	booktitle = {2017 36\textsuperscript{th} Chinese Control Conference (CCC)}, 
	title     = {A review of object detection based on convolutional neural network}, 
	year      = {2017},
	volume    = {},
	number    = {},
	pages     = {11104-11109},
	doi       = {10.23919/ChiCC.2017.8029130}
}

@misc{Zhu:2012,
  title     = {Classification of MNIST Handwritten Digit Database using Neural Network},
  author    = {Zhu, Wan},
  year      = {2012},
  institute = {Australian National University},
  note      = {\href{../../ExterneDokumente/Dataset/b6616d5470ebb13c17650b70549a851c7b28.pdf}{[pdf]}},
}

@misc{Ziegler:2015,
  title  = {Neuronale Netze – Teil 2},
  author = {Ziegler, Wolfgang},
  year   = {2015},
  note   = {Eingesehen am 26.01.2020 [online]},
  url    = {https://entwickler.de/online/neuronale-netze-teil-2-159753.html},
  key    = {Bias}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
















%Article{Krizhevsky:2017b,