%%%%%%
%
% $Autor: Wings $
% $Datum: 2020-01-18 11:15:45Z $
% $Pfad: WuSt/Skript/Produktspezifikation/powerpoint/ImageProcessing.tex $
% $Version: 4620 $
%
%%%%%%


\section{\glqq Hello World 3\grqq - Erkennung von Flaschen}\label{TrainFlaschen}

In diesem Abschnitt wird ein neuronales Netz trainiert, um Flaschen zu erkennen. In den bisherigen Beispielen wurde ein bestehender Datensatz verwendet. Ausgehend von den bekannten Datensätzen CIFAR10 und CIFAR100 wird hier ein neuer Datensatz generiert. In diesem Fall handelt es sich um Bilder mit drei Farbkanälen und 32$\times$32-Pixel. Die Bilder sind eindeutig Klassen eindeutig zugeordnet.  


\subsection{Datensatz CIFAR-10 und CIFAR-100}

In diesem Beispiel sollen die Datensätze CIFAR-10 und CIFAR-100 verwendet werden, die von Alex Krizhevsky und seinem Team entwickelt und deshalb nach dem \textbf{C}anadian \textbf{I}nstitute \textbf{f}or \textbf{A}dvanced \textbf{R}esearch benannt wurden. 
Beide Datensätze enthalten 32 $\times$ 32-Pixel große Farbbilder mit drei Farbkanälen, denen entsprechende Kategorien zugeordnet sind, zwischen denen es keine Überschneidungen gibt. \cite{Krizhevsky:2009}

Dabei enthält der Datensatz CIFAR-10 insgesamt 60.000 Bilder in 10 Kategorien (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) mit je 6.000 Bildern. Der Datensatz ist bereits auf 50.000 Trainingsbilder und 10.000 Testbilder aufgeteilt.

Der Datensatz CIFAR-100 hingegen enthält zwar ebenfalls 60.000 Bilder, jedoch unterteilt in 100 Kategorien mit je 600 Bildern. Dabei gibt es zusätzlich 20 Oberkategorien, 
denen jeweils einige der 100 Kategorien zugeordnet sind (siehe \ref{TabCIF100}).

\begin{figure}
  \begin{tabular} {c c} 
\hline
Superclass &	Classes\\
\hline
aquatic mammals & 	beaver, dolphin, otter, seal, whale\\
fish & 	aquarium fish, flatfish, ray, shark, trout\\
flowers & 	orchids, poppies, roses, sunflowers, tulips\\
food containers &	bottles, bowls, cans, cups, plates\\
fruit and vegetables &	apples, mushrooms, oranges, pears, sweet peppers\\
household electrical devices &	clock, computer keyboard, lamp, telephone, television\\
household furniture &	bed, chair, couch, table, wardrobe\\
insects &	bee, beetle, butterfly, caterpillar, cockroach\\
large carnivores &	bear, leopard, lion, tiger, wolf\\
large man-made outdoor things &	bridge, castle, house, road, skyscraper\\
large natural outdoor scenes &	cloud, forest, mountain, plain, sea\\
large omnivores and herbivores &	camel, cattle, chimpanzee, elephant, kangaroo\\
medium-sized mammals &	fox, porcupine, possum, raccoon, skunk\\
non-insect invertebrates &	crab, lobster, snail, spider, worm\\
people &	baby, boy, girl, man, woman\\
reptiles &	crocodile, dinosaur, lizard, snake, turtle\\
small mammals &	hamster, mouse, rabbit, shrew, squirrel\\
trees &	maple, oak, palm, pine, willow\\
vehicles 1 &	bicycle, bus, motorcycle, pickup truck, train\\
vehicles 2 &	lawn-mower, rocket, streetcar, tank, tractor\\
\end{tabular}
  \caption{Kategorien in CIFAR-100}
  \label{TabCIF100}

\end{figure}

\subsection{Laden des Datensatzes}

Die Datensätze können heruntergeladen werden oder direkt über Keras in TensorFlow importiert werden \cite{TensorFlow.14.12.2020,kaggle.21.09.2020,Krizhevsky:2017}:

\medskip

\PYTHON{import tensorflow as tf}

\PYTHON{from tensorflow.keras import datasets}

\PYTHON{(X\_train10, y\_train10), (X\_test10, y\_test10) = \textbackslash}

\PYTHON{\qquad tf.keras.datasets.cifar10.load\_data()}

\PYTHON{(X\_train100, y\_train100), (X\_test100, y\_test100) =  \textbackslash} 

\PYTHON{\qquad tf.keras.datasets.cifar100.load\_data()}


\subsection{Datenvorbereitung}
Der Datensatz CIFAR-10  soll mit den Daten der Kategorie \glqq bottles\grqq{} aus dem Datensatz CIFAR-100 zusammengeführt werden, um daraus einen neuen Datensatz zu bilden. Zu Visualisierungszwecken wird \FILE{pyplot} und zu Zwecken der Manipulation der Datensätze wird \FILE{numpy} importiert. Zudem werden die benötigten Module von \FILE{Keras} importiert und die Datensätze CIFAR-10 und CIFAR-100 werden geladen.

\medskip

\PYTHON{import numpy as np}

\PYTHON{import matplotlib.pyplot as plt}

\PYTHON{import tensorflow as tf}

\PYTHON{from tensorflow.keras import datasets, layers, models}

\PYTHON{(X\_train10, y\_train10), (X\_test10, y\_test10) = \textbackslash}

\PYTHON{\qquad  tf.keras.datasets.cifar10.load\_data()}

\PYTHON{(X\_train100, y\_train100), (X\_test100, y\_test100) = \textbackslash}

\PYTHON{\qquad tf.keras.datasets.cifar100.load\_data()}

\medskip

Die Form der Trainingsdaten kann geprüft werden, in dem man für die Trainingsdaten beider Datensätze die Eigenschaft \PYTHON{.shape} anzeigt:


\medskip

\PYTHON{print('Images Shape: {}'.format(X\_train10.shape))}

\PYTHON{print('Labels Shape: {}'.format(y\_train10.shape))}

\PYTHON{print('Images Shape: {}'.format(X\_train100.shape))}

\PYTHON{print('Labels Shape: {}'.format(y\_train100.shape))}

\medskip

Das Ergebnis lautet:

\medskip

\PYTHON{Images Shape: (50000, 32, 32, 3)}

\PYTHON{Labels Shape: (50000, 1)}

\PYTHON{Images Shape: (50000, 32, 32, 3)}

\PYTHON{Labels Shape: (50000, 1)}

\medskip

Das heißt, sie erhalten je Datensatz 50.000 Trainingsdaten, die aus 32$\times$32- Pixeln in drei Farbkanälen bestehen. 
Zugeordnet wird ein Vektor der Länge 50.000, der die zugehörigen Label enthält. Um zu sehen, in welcher Form die Label kodiert sind, kann man sich die ersten zehn Einträge anschauen:

\medskip

\PYTHON{print(y\_train10[:10])}

\PYTHON{}

\PYTHON{[6]}

\PYTHON{\quad [9]}

\PYTHON{\quad [9]}

\PYTHON{\quad [4]}

\PYTHON{\quad [1]}

\PYTHON{\quad [1]}

\PYTHON{\quad [2]}

\PYTHON{\quad [7]}

\PYTHON{\quad [8]}

\PYTHON{\quad [3]]}

\medskip

Schaut man sich mehrere Einträge an, stellt man fest, dass die zehn Kategorien mit den Ziffern 0 bis 9 kodiert werden. Das heißt, der Vektor mit den Kategorien ist in die OneHotVector-Darstellung zu transformieren.

In Abbildung~\ref{CIF10} sind die ersten 25 Trainingsdaten mit zugehörigen Labels dargestellt. Dies lässt sich einfach programmieren:


\medskip

\PYTHON{plt.figure(figsize=(10,10))}

\PYTHON{for i in range(25):}

\PYTHON{\qquad  plt.subplot(5,5,i+1)}

\PYTHON{\qquad    plt.xticks([])}

\PYTHON{\qquad    plt.yticks([])}

\PYTHON{\qquad    plt.grid(False)}

\PYTHON{\qquad    plt.imshow(X\_train10[i], cmap=plt.cm.binary)}

\PYTHON{\qquad    plt.xlabel(y\_train10[i])}

\PYTHON{plt.show()}

\medskip

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.9\textwidth]{Examples/TrainingFlaschen/CIFAR10}
		\caption{Visualisierung der ersten 25 Trainingsdaten aus dem Datensatz CIFAR-10} 
		\label{CIF10}
	\end{center}
\end{figure}

Analog können Beispiele aus dem Datensatz CIFAR-100 in Abbildung~\ref{CIF100} angezeigt werden:

\medskip

\PYTHON{plt.figure(figsize=(10,10))}

\PYTHON{for i in range(25):}

\PYTHON{\qquad     plt.subplot(5,5,i+1)}

\PYTHON{\qquad     plt.xticks([])}

\PYTHON{\qquad     plt.yticks([])}

\PYTHON{\qquad     plt.grid(False)}

\PYTHON{\qquad     plt.imshow(X\_train100[i], cmap=plt.cm.binary)}

\PYTHON{\qquad     plt.xlabel(y\_train100[i])}

\PYTHON{\qquad plt.show()}
    
\medskip

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.9\textwidth]{Examples/TrainingFlaschen/CIFAR100}
		\caption{Visualisierung der ersten 25 Trainingsdaten aus dem Datensatz CIFAR-100} 
		\label{CIF100}
	\end{center}
\end{figure}

Es ist zu erkennen, dass die Kategorien in alphabetischer Reihenfolge durchnummeriert sind (0-apples, 1-aquarium fish...; vgl. Tabelle~\ref{TabCIF100}). Demnach hat die Kategorie \glqq bottles\grqq{} den Index 9, was sich durch Anzeige der entsprechenden Bilder überprüfen lässt.

Da das Ziel ist, nur die Bilder der Kategorie \glqq bottles\grqq{} zu CIFAR-10 hinzuzufügen, muss der CIFAR-100-Datensatz so gefiltert und reduziert werden, dass nur die Bilder mit dem Index 9 übrig bleiben. Dazu werden alle Einträge mit dem Wert 9 im Labelvektor gesucht  und die so erhaltene Struktur auf die Trainingsdaten angewendet, um sie auf diese Einträge zu reduzieren. Da wir die gefilterten  Daten einem Datensatz hinzufügen wollen, der den Index 9 bereits für eine vorhandene Kategorie vergeben hat, wird er in diesem Schritt auch den Index auf 10 geändert.
 
\medskip

\PYTHON{idx = (y\_train100 == 9).reshape(X\_train100.shape[0])}

\PYTHON{X\_train100 = X\_train100[idx]}

\PYTHON{y\_train100 = y\_train100[idx]}

\PYTHON{for i in range(len(y\_train100)):}

\PYTHON{\qquad    y\_train100[i]=10 }

\medskip


Mit der Abfrage

\medskip

\PYTHON{len(X\_train100)}

\medskip


wird festgestellt, dass sich die Anzahl der Trainingsdaten im CIFAR-100-Datensatz von 50.000 auf 500 reduziert hat, was genau der Anzahl an erwarteten Einträgen pro Kategorie entspricht. Für eine grobe Überprüfung können wir uns erneut die ersten 25 Einträge aus dem modifizierten Datensatz CIFAR-100 anzeigen lassen. Wie in Abbildung~\ref{CIF100b} zu erkennen ist, bestehen diese sowohl  nach dem Bild als auch nach dem Label zu urteilen ausschließlich aus der gewünschten Kategorie.
 
 \begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.9\textwidth]{Examples/TrainingFlaschen/CIFAR100b}
		\caption{Visualisierung der ersten 25 Trainingsdaten in dem gefilteretn CIFAR-100-Datensatz} 
		\label{CIF100b}
	\end{center}
\end{figure}
 

Leider konnten die beiden Datensätze nicht direkt zusammengeführt werden. In diesem Fall hätte die hinzugefügte Kategorie lediglich 500 Bilder, während für die anderen Kategorien jeweils 5.000 Bilder vorliegen. Dadurch würde diese Kategorie nicht ausreichend trainiert und weniger gut als die anderen Kategorien erkannt werden. Nun stehen zwei Möglichkeiten zur Verfügung. Aus den 500 Bildern könnte 5000 Bilder generiert werden, dies ist aber aufwendig. Die Alternative ist die Reduzierung der Bilder der anderen Kategorien auf 500. Hierzu wird ein ähnliches Verfahren nun auch für die Daten aus dem Datensatz CIFAR-10 angewendet, um alle Kategorien gleichmäßig im neuen Datensatz zu repräsentieren.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%hier weiter


\medskip

\PYTHON{X\_train10\_red = [None]*5000}

\PYTHON{y\_train10\_red = [None]*5000}

\PYTHON{for i in range(10):}

\PYTHON{\qquad idx = (y\_train10 == i).reshape(X\_train10.shape[0])}

\PYTHON{\qquad x=X\_train10[idx]}

\PYTHON{\qquad y=y\_train10[idx]}

\PYTHON{\qquad X\_train10\_red[i*500:i*500+500] = x[0:500]}

\PYTHON{\qquad y\_train10\_red[i*500:i*500+500] = y[0:500] }

\medskip
 
 Mit dem Befehl \PYTHON{concatenate} aus \FILE{numpy} können die beiden Datensätze, unsere modifizierten Versionen von CIFAR-10 und CIFAR-100, nun miteinander verbunden werden.
 
\medskip

\PYTHON{X\_train = np.concatenate((X\_train10, X\_train100))}

\PYTHON{y\_train = np.concatenate((y\_train10, y\_train100))}

\medskip

Die Länge der beiden Arrays beträgt nun 5500 Einträge. Um zu sehen, wie die beiden Datensätze zusammengefügt wurden, können die Einträge 4999 bis 5023 des neu erstellten Datensatzes angeschaut werden. In Abbildung~\ref{Mod1} lässt sich erkennen, dass die Daten des modifizierten Datensatzes CIFAR-100  an die Daten des Datensatzes CIFAR-10 angehangen wurden. Außerdem liegen auch in dem von uns reduzierten Datensatzes  CIFAR-10 die Kategorien nun in geordneter Reihenfolge vor.
  
 \begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.9\textwidth]{Examples/TrainingFlaschen/Mod1}
		\caption{Visualisierung des Übergangs zwischen den beiden Datensätzen} 
		\label{Mod1}
	\end{center}
\end{figure}  

Um dies zu korrigieren, wird der erstellte Datensatz durchmischt. Wichtig ist dabei, dass Bilder und Label in der gleichen Art durchmischt werden, damit sie weiterhin zusammenpassen. Dafür wird die Hilfsvariable \PYTHON{shuffler} definiert, die die Art vorgibt, in der die beiden Arrays zufällig aber beide gleichermaßen durchmischt werden.

 
\medskip

\PYTHON{shuffler = np.random.permutation(len(X\_train))}

\PYTHON{X\_train = X\_train[shuffler]}

\PYTHON{y\_train = y\_train[shuffler]}

\medskip

Dann sieht der gleiche Ausschnitt aus dem Datensatz aus wie in Abbildung~\ref{Mod2}.

 \begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.9\textwidth]{Examples/TrainingFlaschen/Mod2}
		\caption{Visualisierung des Übergangs generierten Datensatzes} 
		\label{Mod2}
	\end{center}
\end{figure}  

Zuletzt wird aus den Labels eine OneHotVector-Darstellung erstellt:

\medskip

\PYTHON{y\_train = tf.keras.utils.to\_categorical(y\_train)}

\medskip

Die Daten sind nun in folgender Form:

\medskip

\PYTHON{print(X\_train.shape)}

\PYTHON{print(y\_train.shape)}

\PYTHON{print(y\_train[1])}

\medskip


\PYTHON{(5500, 32, 32, 3)}

\PYTHON{(5500, 11)}

\PYTHON{[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]}

\medskip

Die gleichen Schritte zur Modifizierung und Zusammenführung der Datensätze müssen auch für die Testdaten durchlaufen werden. Der Code zur Erstellung des Datensatzes ohne die zusätzlichen Schritte zur Visualisierung ist in dem Listin~\ref{cifar10:complete} nachfolgend dargestellt.

\begin{code}[H]
  \lstinputlisting[language=Python]{../Code/JetsonNano/Datensatz.py}
  \caption{Generierung eines Datensatzes aus den Datensätzen CIFAR-10 und CIFAR-100}\label{cifar10:complete}
\end{code}

\subsection{Aufbau und Training des Modells}

Das Training soll mit dem zuvor erstellten Datensatz, zu Vergleichszwecken aber auch mit dem vollständigen CIFAR-10-Datensatz durchgeführt werden. Zudem sollen aber auch verschiedene Netzarchitekturen -- zum einen das aus dem MNIST-Tutorial bekannt Netz und zum anderen die Architektur von AlexNet -- verwendet sowie verschiedene Batchgrößen getestet werden. Deshalb wird im Quellcode zu Beginn eine Eingabe der Parameter vorgesehen, wobei \PYTHON{Dataset=1} für den CIFAR-10-Datensatz und \PYTHON{Dataset=2} für den eigenen Datensatz steht, \PYTHON{Model=1} für das MNIST-Modell und \PYTHON{Model=2} für die AlexNet-Architektur. Als Epochenanzahl wird 100 verwendet und an einzelnen Stellen getestet, ob die doppelte Anzahl an Epochen zu einem veränderten Ergebnis führt. Laut verschiedenen Quellen bietet es sich an, als Batchgröße zunächst 32 zu wählen und zusätzlich weitere Zweierpotenzen (64, 128, 256) auszuprobieren.

Im ersten Schritt werden basierend auf der Auswahl des Datensatzes die Bilder mit zugehörigen Labels geladen. Daraufhin kann das in der Parameterauswahl angegebene Modell aufgebaut und die Daten entsprechend vorbereitet werden. Wurde \PYTHON{Modell=1} ausgewählt, wird ein einfaches neuronales Netz aufgebaut, wie es in dem MNIST-Tutorial in \cite{Heise:2020} (auf S.68) beschrieben ist. Hierfür werden im Vorfeld die Bilder in den Wertebereich 0 bis 1 normalisiert.

Wurde \PYTHON{Modell=2} ausgewählt, wird AlexNet aufgebaut, wie es bei \cite{Alake:2020} zu sehen ist. Die Vorbereitung der Datensätze wird etwas verkürzt vorgenommen als hier dargestellt, da bei Verwendung von \PYTHON{tf.data.Dataset.from\_tensor\_slices} im Training Fehlermeldungen bei den verwendeten Versionen und Konfigurationen auftreten. Stattdessen bleiben die Bilddaten in der Tensordarstellung. Diese werden auf einen Mittelwert von Null und Standardabweichung 1 mit der Build-In-Funktion \PYTHON{tf.image.per\_image\_standardization} normalisiert und die Größe an die von AlexNet vorgegebene Größe von 227 $\times$ 227 angepasst.

Für das Modell 1 wird auch das Kompilieren des Modells mit Optimierer und Verlustfunktion so ausgeführt wie in der Referenz. Für AlexNet wird ebenfalls wie in der Referenz der Optimierer \PYTHON{tf.optimizers.SGD(lr=0.001)} verwendet. Dabei steht SGD für \glqq stochastic gradient descent\grqq, also stochastisches Gradientenabstiegsverfahren. Der Parameter \PYTHON{lr} gibt die Lernrate an, die bestimmt, in wie großen Schritten die Gewichte jeweils entlang des Gradienten angepasst werden sollen.

Die Erstellung des \FILE{logfiles} erfolgt wie gehabt, es wird lediglich der Dateiname entsprechend der zu Beginn des Programmdurchlaufs gewählten Parameter benannt, um diese im Nachhinein zuordnen zu können. Im Training selbst besteht der einzige Unterschied darin, dass für das Modell 1 eine Abspaltung der Validierungsdaten für das Training über den Befehl \PYTHON{validation\_split} erfolgt, während für das Modell 2 entsprechend der genutzten Vorlage die Validierungsdaten im Vorfeld definiert wurden (letzte 20 \% der Trainingsdaten) und im Training als \PYTHON{validation\_data} angegeben werden können.

Nach Beendigung des Trainings wird das Modell mit den Testdaten evaluiert und das Ergebnis dessen sowie die verstrichene Trainingszeit und das Modell selbst, letzteres als \PYTHON{saved\_model.pb}, gespeichert, erneut unter Angabe der gewählten Parameter im entsprechenden Ordnernamen. Das beschriebene zum Training verwendete Programm \FILE{Training\_CIFAR.py} ist im Listing~\ref{cifar10:complete2} in voller Länge zu finden.

\begin{code}
  \lstinputlisting[language=Python,firstnumber=1]{../Code/JetsonNano/Training_CIFAR.py}
  \caption{Training eines Datensatzes aus den Datensätzen CIFAR-10 und CIFAR-100}
  \label{cifar10:complete2}
\end{code}


\subsection{Historie des Trainings und Visualisierung mit TensorBoard}

Die mit TensorBoard visualisierten Verläufe des Trainings für die verschiedenen gewählten Parameter sind in der Tabelle~\ref{VisTrain1} für den Datensatz CIFAR-10 und in Tabelle~\ref{VisTrain2} für den modifizierten Datensatz zu sehen.

\medskip


\begin{longtable} {|c | c |} 
\caption{Visualisierung der Trainingsverläufe mit dem Datensatz CIFAR10}
\label{VisTrain1}\\
\hline
\multicolumn{2}{|c|}{Dataset 1 Model 1 Epochs 100 Batch Size 32}\\
\hline
 & \\
% \includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/plots/Dataset1Model1Epochs100BatchSize32/acc}
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset1Model1Epochs100BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset1Model1Epochs100BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 1 Model 2 Epochs 100 Batch Size 32}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset1Model2Epochs100BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset1Model2Epochs100BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\end{longtable}

\begin{longtable} {|c | c |} 
\caption{Visualisierung der Trainingsverläufe mit dem modifizierten Datensatz}
\label{VisTrain2}\\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 1 Epochs 100 Batch Size 32}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 1 Epochs 200 Batch Size 32}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs200BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs200BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 1 Epochs 100 Batch Size 64}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize64/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize64/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 1 Epochs 100 Batch Size 128}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize128/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize128/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 1 Epochs 100 Batch Size 256}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize256/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model1Epochs100BatchSize256/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 2 Epochs 100 Batch Size 32}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 2 Epochs 200 Batch Size 32}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs200BatchSize32/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs200BatchSize32/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 2 Epochs 100 Batch Size 64}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize64/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize64/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 2 Epochs 100 Batch Size 128}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize128/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize128/loss}\\
Accuracy & Loss \\
\hline
\multicolumn{2}{|c|}{Dataset 2 Model 2 Epochs 100 Batch Size 256}\\
\hline
 & \\
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize256/acc}
  &	
\includegraphics[width=0.49\textwidth]{Examples/TrainingFlaschen/Plots/Dataset2Model2Epochs100BatchSize256/loss}\\
Accuracy & Loss \\
\hline
\end{longtable}

Tabelle~\ref{TabTrain} zeigt die Werte der Genauigkeit und Verlustfunktion zu Ende des Trainings für Training, Validierung und die an das Training
anschließende Evaluierung mit den Testdaten.

\begin{table}[ht]
\caption{Modellqualität und Trainingszeit für verschiedene Parameter: D-Datensatz, M-Modell, E-Epochen, B-Batchgröße}
\label{TabTrain}
\begin{tabular} {| c | c | c | c | c | c | c | c | c | c | c |}
\firsthline
\multicolumn{4}{| c |}{Parameters} & \multicolumn{2}{ c }{training} & \multicolumn{2}{| c |}{validation} & \multicolumn{2}{ c |}{test} & \\
\hline
D & M & E & B & accuracy & loss & accuracy & loss & accuracy & loss & train.\\
 & & & & & & & & & & time\\
 \hline
 1& 1 & 100 & 32 & 0.9498 & 0.1522 & 0.7109 & 1.586 & 0.7066 & 1.567 & 65.1\\
  \hline
1 & 2 & 100 & 32 & 0.9937 & 0.0219 & 0.7356 & 1.323 & 0.7316 & 1.363 & 1,366.2\\
 \hline
2 & 1 & 100 & 32 & 0.9782 & 0.0647 & 0.5482 & 3.441 & 0.5367 & 3.306 & 7.4\\
\hline
2 & 1 & 200 & 32 & 0.9914 & 0.0299 & 0.5309 & 4.229 & 0.5224 & 4.350 & 14.8\\
\hline
2 & 1 & 100 & 64 & 0.9861 & 0.0460 & 0.5564 & 2.990 & 0.5427 & 3.157 & 6.1\\
\hline
2 & 1 & 100 & 128 & 0.9793 & 0.0663 & 0.5355 & 2.994 & 0.5392 & 3.060 & 5.6\\
\hline
2 & 1 & 100 & 256 & 0.9616 & 0.1003 & 0.5491 & 2.642 & 0.5543 & 2.602 & 5.2\\
\hline
2 & 2 & 100 & 32 & 0.9932 & 0.0413 & 0.5836 & 1.598 & 0.5582 & 1.730 & 152.3\\
\hline
2 & 2 & 200 & 32 & 0.9989 & 0.0094 & 0.6073 & 1.715 & 0.5578 & 1.954 & 303.0\\
\hline
2 & 2 & 100 & 64 & 0.9884 & 0.0548 & 0.5773 & 1.562 & 0.5603 & 1.679 & 151.9\\
\hline
2 & 2 & 100 & 128 & 0.9891 & 0.0489 & 0.6036 & 1.537 & 0.5602 & 1.686 & 151.4\\
\hline
2 & 2 & 100 & 256 & 0.9857 & 0.0570 & 0.5936 & 1.561 & 0.5569 & 1.727 & 154.6\\
 \hline
\end{tabular}
\end{table}

\medskip

Wie zu erwarten ist, kann mit dem vollständigen Datensatz CIFAR-10 bei Training mit AlexNet eine höhere Genauigkeit erreicht werden, da mit wesentlich mehr Bildern trainiert wurde. Bei dem einfacheren Modell scheint der kleine Datensatz im Training eine hohe Genauigkeit zu erzielen, jedoch scheint hier Overfitting stattzufinden, denn die Testgenauigkeit ist für den kleinen, modifizierten Datensatz sehr viel kleiner als die Trainingsgenauigkeit. Gleichzeitig wird jedoch für das Training mit dem vollständigen Datensatz CIFAR-10 bei der AlexNet-Architektur eine Trainingszeit von fast einem ganzen Tag benötigt mit den Spezifikationen RAM 64 GB, Intel i9 9900k Prozessor, 8 Kerne, 3600 MHz.

Es ist zu erkennen, dass ein Training mit 100 Epochen absolut ausreichend ist. Die Ergebnisse variieren leicht mit der Batchgröße, hier ist aber keine klare Schematik zu erkennen.

Die erreichten Genauigkeiten sind nicht besonders hoch. Dies überrascht jedoch nicht, wenn man den reduzierten Trainingsaufwand bedenkt und einen Vergleich mit den von den AlexNet-Entwicklern mit AlexNet erzielten Ergebnissen anstellt. Auch hier wurden trotz Verwendung von über 1.2 Millionen hochauflösenden Bildern mit dem Datensatz ImageNet noch bei eine Top-1-Fehlerrate von 37,5 \% beobachtet. Insofern sind die hier mit TensorFlow erzielten Ergebnisse mit weniger Bildern in geringer Auflösung plausibel wenn auch nicht zufriedenstellend.

